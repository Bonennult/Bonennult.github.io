

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/8.png">
  <link rel="icon" type="image/png" href="/img/8.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="Glooow">
  <meta name="keywords" content="">
  <title>矩阵分析学习笔记 - 你是下雨天</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.4.0/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.8.7","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"onlypost":false},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}}};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.3.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Glooow</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Tags
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" href="javascript:">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="矩阵分析学习笔记">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2020-02-03 21:08" pubdate>
        February 3, 2020 pm
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      6.2k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      91
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">矩阵分析学习笔记</h1>
            
            <div class="markdown-body">
              <p>在网上自学矩阵分析的一些笔记，主要是总结一些结论性的东西，并没有太多证明。对于非数学专业的学生，笔者认为抛开证明的细节，从更加具象的角度理解矩阵可能会有更清晰的理解。</p>
<p>未完待续，更新中 …</p>
<p>参考资料：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/matrix-learning">知乎专栏</a></p>
<a id="more"></a>
<hr>
<h2 id="1-线性代数基础——空间"><a href="#1-线性代数基础——空间" class="headerlink" title="1. 线性代数基础——空间"></a>1. 线性代数基础——空间</h2><ul>
<li><p>几个基本的概念</p>
<ul>
<li><p><strong>数域</strong>：对<strong>加减乘除</strong>四则基本<strong>运算封闭</strong>的<strong>数集</strong></p>
<ul>
<li>注意：首先<strong>数域</strong>的概念针对的是<strong>数集</strong>，不是向量也不是矩阵；其次要求对四则基本运算封闭。</li>
</ul>
</li>
<li><p><strong>线性空间</strong>：需满足以下条件</p>
<script type="math/tex; mode=display">
\begin{alignat}{1}
&1)\ \alpha+\beta=\beta+\alpha     &5)\ 1 a=\alpha\notag\\
&2)\ (\alpha+\beta)+\gamma=\alpha+(\beta+\gamma)   &6)\ k(l \alpha)=(k l) \alpha\notag\\
&3)\ \exists 0 \in V, \forall \alpha \in V, 有 \alpha+0=\alpha &7)\ (k+l) \alpha=k \alpha+l \alpha\notag\\
&4)\ \forall \alpha \in V, \exists \beta \in V, s.t.\  \alpha+\beta=0 \qquad &8)\ k(\alpha+\beta)=k \alpha+l \beta\notag\\
\end{alignat}\notag</script></li>
<li><p><strong>子空间</strong>：</p>
</li>
<li><p>空间的<strong>维数</strong>：基的个数</p>
</li>
<li><p><strong>平凡子空间</strong>：V 空间的子空间只有 0 空间和 V 空间本身</p>
</li>
<li><p><strong>非平凡子空间</strong>：除了平凡子空间，其他所有子空间</p>
</li>
<li><p>子空间的<strong>直和</strong>：$V_1 \cap V_2=\{0\}$ 时，直和可定义为 $V_1 \bigoplus V_2$，主要是为了保证<strong>分解的唯一性</strong>。可以推广到多个子空间 $V_i (\sum_{j\ne i}V_j) = \{0\}$</p>
<ul>
<li>注：$V_1,V_2$ 相互可能不是正交的，比如二维平面中不正交的两个基</li>
</ul>
</li>
<li><p><strong>酉空间</strong>：欧几里得空间推广到<strong>复数域</strong></p>
</li>
</ul>
</li>
</ul>
<hr>
<h2 id="2-投影"><a href="#2-投影" class="headerlink" title="2. 投影"></a>2. 投影</h2><ul>
<li><strong>变换</strong>：线性空间到自身的映射 $T:V(C)\to V(C)$</li>
<li><strong>线性变换</strong>：<ul>
<li>$T(\alpha+\beta) = T(\alpha)+T(\beta)$</li>
<li>$T(k\alpha) = kT(\alpha)$</li>
</ul>
</li>
<li><strong>投影</strong>：$T$ 是 $V(C)$ 上的投影， $\iff T^2=T$</li>
</ul>
<blockquote>
<p><strong>定理 1</strong>：设 $T$ 是 $V(C)$ 上的投影，则 $V(C) = R(T)\bigoplus N(T)$</p>
<p><strong>定理 2</strong>：设 $V(C) = V_1\bigoplus V_2$，则存在投影 $T$ 使得 $R(T)=V_1, N(T)=V_2$</p>
<p><strong>Remark</strong>：根据投影的定义 $T^2=T$，可以形象理解为<strong>降维</strong>操作，也即投影过程不可逆，投影一次后即进入<strong>值域</strong> $R(T)$，也即是 $V(C)$ 的一个低维子空间。</p>
</blockquote>
<ul>
<li><p><strong>投影矩阵</strong>：投影 $T$ 为线性变换，可以用矩阵 $A$ 表示<br><img src="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/proj.jpg" srcset="/img/loading.gif" alt="线性变换"></p>
</li>
<li><p><strong>幂等矩阵</strong>：满足 $A^2=A$，有如下性质</p>
<ul>
<li>$A^H$ 与 $(E-A)$ 也是幂等矩阵</li>
<li>$A$ 的特征值只有 0 和 1，且可以对角化</li>
<li>$rank(A)=tr(A)$</li>
<li>$A(E-A)=(E-A)A$</li>
<li>$Aa = a, \iff a\in R(A)$</li>
<li>$N(A)=R(E-A), R(A)=N(E-A)$</li>
</ul>
<blockquote>
<p>上面的性质均可由<strong>幂等矩阵</strong>的性质导出</p>
</blockquote>
</li>
<li><p><strong>正交投影</strong>：$\iff R^{\perp}(T) = N(T) \iff A^H=A$</p>
</li>
</ul>
<blockquote>
<p><strong>Remark</strong>：</p>
<ul>
<li>实际上对于正交投影 $A$，可以写成以下形式</li>
</ul>
<p><img src="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/decom.jpg" srcset="/img/loading.gif" alt="正交投影分解"></p>
<ul>
<li>是否存在<strong>非正交投影</strong>呢？非正交投影又是什么形式呢？<br>只需要将中间的对角阵换成Jordan标准型的形式？</li>
</ul>
</blockquote>
<hr>
<h2 id="3-Jordan标准型"><a href="#3-Jordan标准型" class="headerlink" title="3. Jordan标准型"></a>3. Jordan标准型</h2><p>注：此部分是矩阵论的基本定理之一，非常重要！！！</p>
<blockquote>
<p><strong>定理 1</strong>：任意 n 阶矩阵 $A$，一定存在 n 阶<strong>可逆矩阵</strong> P 使得</p>
<script type="math/tex; mode=display">
P^{-1} A P=\left(\begin{array}{cccc}
{J_{1}} & {} & {} & {} \\
{} & {J_{2}} & {} & {} \\
{} & {} & {\ddots} & {} \\
{} & {} & {} & {J_{k}}
\end{array}\right)=J \notag</script><p>其中 $J_i$ 为 Jordan 块。有以下几个结论</p>
<ol>
<li>Jordan 块的个数是<strong>线性无关特征向量的个数</strong></li>
<li>矩阵可<strong>对角化</strong>当且仅当 $k=n$</li>
<li>对于某个特征值，Jordan 块个数为<strong>几何重数</strong>，所有 Jordan 块的阶数之和为<strong>代数重数</strong>（特征值多项式根的阶数即为代数重数，永远有几何重数不大于代数重数）</li>
<li>特征值的几何重数不大于代数重数</li>
<li>矩阵不同特征值对应的<strong>特征向量线性无关</strong></li>
</ol>
</blockquote>
<hr>
<h2 id="4-初等矩阵与酉矩阵"><a href="#4-初等矩阵与酉矩阵" class="headerlink" title="4. 初等矩阵与酉矩阵"></a>4. 初等矩阵与酉矩阵</h2><h3 id="4-1-初等变换矩阵"><a href="#4-1-初等变换矩阵" class="headerlink" title="4.1 初等变换矩阵"></a>4.1 初等变换矩阵</h3><blockquote>
<p><strong>定义</strong>：设 $\boldsymbol{u,v}\in \mathbb{C}^n,\sigma\in \mathbb{C}$，则称 $E(\boldsymbol{u,v},\sigma)=E-\sigma\boldsymbol{uv}^H$ 为<strong>初等变换矩阵</strong></p>
</blockquote>
<ul>
<li><p><strong>初等变换</strong>矩阵性质</p>
<ul>
<li>特征向量<ul>
<li>若 $\boldsymbol{u\in v^{\perp}}$，设 $\boldsymbol{u_1,…,u_{n-1}}$ 是 $v^\perp$ 的一组基，则 $E(\boldsymbol{u,v},\sigma)$ 的一组<strong>线性无关</strong>的特征向量为 $\boldsymbol{u_1,…,u_{n-1}}$</li>
<li>若 $\boldsymbol{u\notin v^{\perp}}$，设 $\boldsymbol{u_1,…,u_{n-1}}$ 是 $v^\perp$ 的一组基，则 $E(\boldsymbol{u,v},\sigma)$ 的一组<strong>线性无关</strong>的特征向量为 $\boldsymbol{u,u_1,…,u_{n-1}}$</li>
</ul>
</li>
<li>特征值 $\lambda(E(\boldsymbol{u,v},\sigma))=\{1,…,1,1-\sigma v^H u\}$</li>
<li>行列式 $det(E(\boldsymbol{u,v},\sigma))=1-\sigma v^H u$</li>
<li>逆矩阵 $E(u, v, \sigma)^{-1}=E\left(u, v, \frac{\sigma}{\sigma v^{H} u-1}\right),\left(1-\sigma v^{H} u \neq 0\right)$</li>
<li>非零向量 $\boldsymbol{a,b}\in\mathbb{C}^n$，存在 $\boldsymbol{u,v},\sigma$ 使得 $E(u, v, \sigma) a=b,\left(\sigma u=\frac{a-b}{v^{H} a}\right)$</li>
</ul>
<blockquote>
<p><strong>Remarks</strong></p>
<ol>
<li>前两个性质可以根据 $u,v$ 的垂直关系直观想象。当 $u\perp v$ 时，此时 $E$ 对于特征值 $1$ 的代数重数为 $n$，而几何重数为 $n-1$（注意此时出现了代数重数大于几何重数的情况！）；否则，$E$ 对于特征值 $1$ 的代数重数和几何重数为 $n-1$，且有另一个特征值 $1-\sigma v^H u$</li>
</ol>
</blockquote>
</li>
<li><p>所有初等变换可以用上述定义表示</p>
<ul>
<li>置换 ${E_{i j}=E-\left(e_{i}-e_{j}\right)\left(e_{i}-e_{j}\right)^{T}=E\left(e_{i}-e_{j}, e_{i}-e_{j}, 1\right)}$</li>
<li>相消 ${E_{i j}(k)=E+k e_{j} e_{i}^{T}=E\left(e_{j}, e_{i},-k\right)}$</li>
<li>数乘 ${E_{i}(k)=E-(1-k) e_{i} e_{i}^{T}=E\left(e_{i}, e_{i}, 1-k\right)}$</li>
</ul>
</li>
</ul>
<h3 id="4-2-初等酉矩阵"><a href="#4-2-初等酉矩阵" class="headerlink" title="4.2 初等酉矩阵"></a>4.2 初等酉矩阵</h3><blockquote>
<p><strong>定义</strong>：设 $\boldsymbol{u}\in \mathbb{C}^n$ 且 $u^H u =1$，则称 $H(U)=E(\boldsymbol{u,U},2)=E-2\boldsymbol{uu}^H$ 为<strong>初等酉矩阵</strong>，或者<strong>Householder矩阵</strong></p>
</blockquote>
<ul>
<li><strong>Householder</strong>变换性质<ul>
<li>$H^H=H=H^{-1}$</li>
<li>$H(\boldsymbol{u})(\boldsymbol{a}+r\boldsymbol{u})=\boldsymbol{a}-r\boldsymbol{u}, \forall a\in v^\perp, r\in\mathbb{C}$（镜像变换）</li>
<li>范数不变性：$||Hx||=||x||$</li>
<li>保持随机向量的协方差</li>
<li>可用于数值算法构造正交基</li>
</ul>
</li>
</ul>
<h3 id="4-3-酉变换"><a href="#4-3-酉变换" class="headerlink" title="4.3 酉变换"></a>4.3 酉变换</h3><ul>
<li><strong>酉变换与酉矩阵</strong><ol>
<li>保持<strong>内积</strong>不变</li>
<li>保持长度不变</li>
<li>保持夹角不变</li>
<li>保持形状不变</li>
</ol>
</li>
<li>内积的定义，比如连续区间中对连续函数的定义</li>
</ul>
<hr>
<h2 id="5-欧氏空间中的度量（？）"><a href="#5-欧氏空间中的度量（？）" class="headerlink" title="5. 欧氏空间中的度量（？）"></a>5. 欧氏空间中的度量（？）</h2><ul>
<li><p><strong>内积</strong>：满足 4 条性质</p>
<ol>
<li>$(x,x)\ge0,且(x,x)=0\iff x=0$</li>
<li>$(x,y)=\overline{(y,x)},\forall x,y\in V(P)$</li>
<li>$(\lambda x,y)=\bar{\lambda}(x,y),\forall \lambda\in P,\forall x,y\in V(P)$</li>
<li>$(x+y,z)=(x,z)+(y,z),\forall x,y,z\in V(P)$</li>
</ol>
</li>
<li><p><strong>线性流形</strong>：$P=r_{0}+V_{1}=\left\{r_{0}+\alpha | \alpha \in V_{1}\right\}$</p>
<ul>
<li>实际上就是将子空间进行平移</li>
</ul>
</li>
<li><p>n 维空间中的<strong>体积</strong></p>
<ol>
<li>$V(\alpha_1)=||\alpha_1||$</li>
<li>$V\left(\alpha_{1}, \alpha_{2}, \cdots, \alpha_{n}\right)=V\left(\alpha_{1}, \alpha_{2}, \cdots, \alpha_{n-1}\right) \bullet h_{n}$，其中 $h_n$ 是 $\alpha_n$ 到 $L(\alpha_{1}, \alpha_{2}, \cdots, \alpha_{n-1})$ 的距离</li>
</ol>
</li>
<li><p>Gram 行列式</p>
<script type="math/tex; mode=display">
G\left(\alpha_{1}, \cdots, \alpha_{k}\right)=\left| \begin{array}{cccc}
{\left(\alpha_{1}, \alpha_{1}\right)} & {\left(\alpha_{1}, \alpha_{2}\right)} & {\cdots} & {\left(\alpha_{1}, \alpha_{k}\right)} \\
{\left(\alpha_{2}, \alpha_{1}\right)} & {\left(\alpha_{2}, \alpha_{2}\right)} & {\cdots} & {\left(\alpha_{2}, \alpha_{k}\right)} \\
{\cdots} & {\cdots} & {\cdots} & {\cdots} \\
{\left(\alpha_{k}, \alpha_{1}\right)} & {\left(\alpha_{k}, \alpha_{2}\right)} & {\cdots} & {\left(\alpha_{k}, \alpha_{k}\right)}
\end{array}\right|\notag</script></li>
<li><p>将线性无关向量组 $\alpha_{1}, \alpha_{2}, \cdots, \alpha_{n}$ 正交化之后，Gram 行列式不变，即 $G\left(\alpha_{1}, \alpha_{2}, \cdots, \alpha_{k}\right)=G\left(\beta_{1}, \beta_{2}, \cdots, \beta_{k}\right)$</p>
</li>
<li><p>体积 $V\left(\alpha_{1}, \alpha_{2}, \cdots, \alpha_{n}\right)=\sqrt{G\left(\alpha_{1}, \alpha_{2}, \cdots, \alpha_{n}\right)}$</p>
</li>
<li><p>定理 1：设 $\alpha_{1}, \alpha_{2}, \cdots, \alpha_{k}$ 是 $V_1$ 的一组基，向量 $\alpha$ 到流形 $P=\alpha_0+V_1$ 的距离为 $d^{2}=\frac{G\left(\alpha_{1}, \cdots, \alpha_{k}, \alpha-\alpha_{0}\right)}{G\left(\alpha_{1}, \cdots, \alpha_{k},\right)}$</p>
</li>
<li><p>定理 2：线性流形 $P_1=\alpha_0+V_1$ 和 $P_2=\alpha_0+V_1$ 之间的距离等于 $\alpha_1-\alpha_2$ 关于线性子空间 $V=V_1+V_2$ 的正交分量长度</p>
</li>
</ul>
<hr>
<h2 id="6-Kronecker积"><a href="#6-Kronecker积" class="headerlink" title="6. Kronecker积"></a>6. Kronecker积</h2><ul>
<li>性质<ul>
<li>$E_m\bigotimes E_n = E_{mn}$</li>
<li></li>
</ul>
</li>
</ul>
<hr>
<h2 id="7-范数"><a href="#7-范数" class="headerlink" title="7. 范数"></a>7. 范数</h2><h3 id="7-1-向量范数"><a href="#7-1-向量范数" class="headerlink" title="7.1 向量范数"></a>7.1 向量范数</h3><ul>
<li>范数：刻画向量大小的度量，需要满足以下三条性质<ol>
<li>正定性：$||x||\ge0,且||x||=0\iff x=0$</li>
<li>齐次性：$||\lambda x||=|\lambda|\cdot ||x||,\lambda\in R,x\in C^n$</li>
<li>三角不等式：$||x+y||\le ||x||+||y||,\forall x,y\in C^n$</li>
</ol>
</li>
<li>范数与内积的关系是什么？</li>
<li>导出性质<ul>
<li>$||0||=0$</li>
<li>$x\ne0时,||\frac{1}{||x||}x||=1$</li>
<li>$||-x||=||x||,\forall x\in C^n$</li>
<li>$\vert \Vert x\Vert-\Vert y\Vert \vert \le \Vert x-y \Vert$</li>
</ul>
</li>
<li>常用范数<ul>
<li>1范数：$|x|_{1}=\sum_{i=1}^{n}\left|x_{i}\right|$</li>
<li>2范数：$|x|_{2}=\left(\sum_{i=1}^{n}\left|x_{i}\right|^{2}\right)^{1 / 2}$</li>
<li>$\infty$范数：$|x|_{\infty}=\max _{1 \leq i \leq n}\left|x_{i}\right|$</li>
<li>p范数(Holder范数)：$|x|_{p}=\left(\sum_{i=1}^{n}\left|x_{i}\right|^{p}\right)^{1 / p} \quad 1 \leq p&lt;\infty$<ul>
<li>p可取<strong>正整数</strong></li>
<li>可验证满足三角不等式，需要用到Young不等式和Holder不等式</li>
</ul>
</li>
</ul>
</li>
<li>向量序列的<strong>收敛性</strong></li>
<li>向量范数的<strong>等价性</strong><ul>
<li><img src="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/norm%20equality.jpg" srcset="/img/loading.gif" alt="范数等价性"><br>等价性表示不同范数的量级是相同的，只差一个系数</li>
<li><strong>定理</strong>：$V(P)$ 上的任意两个向量范数均等价</li>
<li><strong>范数等价保证了向量序列的收敛性与范数选取无关</strong>。无穷范数收敛，其他范数一定收敛。其他范数收敛，无穷范数一定收敛。</li>
</ul>
</li>
</ul>
<h3 id="7-2-矩阵范数"><a href="#7-2-矩阵范数" class="headerlink" title="7.2 矩阵范数"></a>7.2 矩阵范数</h3><ul>
<li><p>矩阵可以转化为向量表示</p>
</li>
<li><p>矩阵范数：$A\in P^{m\times n}$，需满足以下条件</p>
<ol>
<li>正定性：$||A||\ge0,且||A||=0\iff A=0$</li>
<li>齐次性：$||\lambda A||=|\lambda|\cdot ||A||,\lambda\in R,A\in P^{m\times n}$</li>
<li>三角不等式：$||A+B||\le ||A||+||B||,\forall A,B\in P^{m\times n}$</li>
<li><strong>相容性</strong>：$\Vert AB \Vert \le \Vert A\Vert\cdot \Vert B\Vert$</li>
</ol>
<blockquote>
<p><strong>Remarks</strong>：这里相容性的定义目的是什么呢？为了放缩方便？</p>
</blockquote>
</li>
<li><p>例如</p>
<ul>
<li>（自相容）$|A|_{m_{1}}=\sum_{j=1}^{n} \sum_{i=1}^{m}\left|a_{i j}\right|$</li>
<li>（不相容）$|A|_{m_{\infty}}=\max _{i, j}\left\{\left|a_{i j}\right|\right\} \quad 1 \leq i \leq m \quad 1 \leq j \leq n$</li>
<li>（自相容）Frobenius范数：$|A|_{m_{2}}=\left(\sum_{j=1}^{n} \sum_{i=1}^{m}\left|a_{i j}\right|^{2}\right)^{\frac{1}{2}}$<ul>
<li>$|\boldsymbol{A}|_{m_{2}}^{2}=\operatorname{tr}\left(\boldsymbol{A}^{\boldsymbol{H}} \boldsymbol{A}\right)=\sum_{i=1}^{n} \lambda_{i}\left(\boldsymbol{A}^{\boldsymbol{H}} \boldsymbol{A}\right)$</li>
<li>对任意酉矩阵$U,V$，$|\boldsymbol{A}|_{m_{2}}^{2}=\left|\boldsymbol{U}^{\boldsymbol{H}} \boldsymbol{A} \boldsymbol{V}\right|_{m_{2}}^{2}=\left|\boldsymbol{U} \boldsymbol{A} \boldsymbol{V}^{\boldsymbol{H}}\right|_{m_{2}}^{2}$</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="7-3-算子范数"><a href="#7-3-算子范数" class="headerlink" title="7.3 算子范数"></a>7.3 算子范数</h3><ul>
<li><p>向量范数与矩阵范数的相容性：$|A x|_{m} \leq|A|_{m}|x|_{m}$ 是否成立</p>
<ul>
<li><strong>定义</strong>：设 $|\cdot|_a$ 是 $P^n$ 上的向量范数，$|\cdot|_m$ 是 $P^{n\times n}$ 上的矩阵范数，且<script type="math/tex; mode=display">
\|A x\|_{a} \leq\|A\|_{m}\|x\|_{a}\notag</script>则称 $|\cdot|_m$ 为与向量范数 $|\cdot|_a$ 相容的矩阵范数</li>
</ul>
</li>
<li><p>算子范数</p>
<ul>
<li><p>设 $|\cdot|_a$ 是 $P^n$ 上的向量范数，$A\in P^{n\times n}$，则</p>
<script type="math/tex; mode=display">
\|\boldsymbol{A}\|_{a}=\underset{\boldsymbol{x} \neq \boldsymbol{\theta}}{\max } \frac{\|\boldsymbol{A} \boldsymbol{x}\|_{a}}{\|\boldsymbol{x}\|_{a}}\left(=\max _{\|u\|_{a}=1}\|A u\|_{a}\right) \notag</script><p>是与向量范数 $|\cdot|_a$ 相容的矩阵范数</p>
</li>
<li><p>推论：算子范数也是相容的矩阵范数，即 $|AB|_a\le|A|_a|B|_a$</p>
</li>
</ul>
</li>
<li><p>常用算子范数</p>
<ul>
<li>极大列和范数：$|\boldsymbol{A}|_{\mathbf{1}}=\mathbf{m}_{\boldsymbol{j}} \mathbf{x}\left(\sum_{\boldsymbol{i}=1}^{\boldsymbol{n}}\left|\boldsymbol{a}_{i j}\right|\right)$</li>
<li>极大行和范数：$|A|_{\infty}=\max _{i}\left(\sum_{j=1}^{n}\left|a_{i j}\right|\right)$</li>
<li>谱范数：$|\boldsymbol{A}|_{2}=\sqrt{r\left(\boldsymbol{A}^{\boldsymbol{H}} \boldsymbol{A}\right)}$<ul>
<li>谱半径：$r(A)=\max _{i}\left|\lambda_{i}\right|$</li>
<li>$|A|_{2}=\left|A^{H}\right|_{2}=\left|A^{T}\right|_{2}=|\bar{A}|_{2}$</li>
<li>$\left|A^{H} A\right|_{2}=\left|A A^{H}\right|_{2}=|A|_{2}^{2}$</li>
<li>对任意酉矩阵$U,V$，$|\boldsymbol{U} \boldsymbol{A}|_{2}=|\boldsymbol{A} \boldsymbol{V}|_{2}=|\boldsymbol{U} \boldsymbol{A} \boldsymbol{V}|_{2}=|\boldsymbol{A}|_{2}$</li>
</ul>
</li>
</ul>
</li>
<li><p>定理</p>
<ul>
<li>$|\boldsymbol{A}|_{2}=\max _{|x|_{2}=|y|_{2}=\mathbf{1}}\left|\boldsymbol{y}^{\boldsymbol{H}} \boldsymbol{A} \boldsymbol{x}\right|$</li>
<li>$|\boldsymbol{A}|_{2}^{2} \leq|\boldsymbol{A}|_{1}|\boldsymbol{A}|_{\infty}$</li>
</ul>
</li>
</ul>
<hr>
<h2 id="8-矩阵分解"><a href="#8-矩阵分解" class="headerlink" title="8. 矩阵分解"></a>8. 矩阵分解</h2><h3 id="8-1-三角分解"><a href="#8-1-三角分解" class="headerlink" title="8.1 三角分解"></a>8.1 三角分解</h3><ul>
<li>三角矩阵<ul>
<li>逆矩阵仍然是三角矩阵</li>
<li>三角矩阵的积仍是三角矩阵</li>
</ul>
</li>
</ul>
<blockquote>
<p> <strong>定理(LU分解)</strong>：设  $A\in C^{n\times n}$，则 $A$ 可<strong>唯一的</strong>分解为</p>
<script type="math/tex; mode=display">
A=U_1 R \notag</script><p>其中 $U_1$ 为酉矩阵，$R$ 为正线上三角矩阵；或者 A 可以<strong>唯一的</strong>分解为</p>
<script type="math/tex; mode=display">
A = L U_2 \notag</script><p>其中 $U_2$ 为酉矩阵，$L$ 为正线下三角矩阵。</p>
<p><strong>推论 1</strong>：对于实数域，则有类似的 <strong>QR分解</strong></p>
<p><strong>推论 2.1</strong>：对于<strong>实对称</strong>矩阵，存在唯一上三角实矩阵</p>
<script type="math/tex; mode=display">
A = R^T R \notag</script><p><strong>推论 2.2</strong>：正定 <strong>Hermite</strong> 矩阵，存在唯一上三角复矩阵</p>
<script type="math/tex; mode=display">
A = R^H R \notag</script></blockquote>
<ul>
<li>任意矩阵的三角分解（非方阵）</li>
</ul>
<h3 id="8-2-谱分解"><a href="#8-2-谱分解" class="headerlink" title="8.2 谱分解"></a>8.2 谱分解</h3><ul>
<li><strong>单纯矩阵</strong>：代数重数等于几何重数</li>
</ul>
<blockquote>
<p><strong>定理</strong>：设 $A\in C^{n\times n}$ 是<strong>单纯矩阵</strong>，则 $A$ 可以分解为一系列<strong>幂等矩阵</strong> $A_i$ 的加权和</p>
<script type="math/tex; mode=display">
A = \sum_{i=1}^n \lambda_i A_i \notag</script><p>其中 $\lambda_i$ 是 $A$ 的特征值</p>
<p><strong>证明</strong>：由单纯矩阵可知</p>
<script type="math/tex; mode=display">
A=P\Lambda P^{-1}=\left(v_{1}, v_{2}, \cdots, v_{n}\right)\left[\begin{array}{cccc}{\lambda_{1}} & {0} & {\cdots} & {0} \\{0} & {\lambda_{2}} & {\cdots} & {0} \\{\cdots} & {\cdots} & {\cdots} & {\cdots} \\{0} & {0} & {\cdots} & {\lambda_{n}}\end{array}\right]\left(\begin{array}{c}{\omega_{1}^{T}} \\{\omega_{2}^{T}} \\{\vdots} \\{\omega_{n}^{T}}\end{array}\right) \notag</script><p>取 $A_i = v_i w_i^T$，$A_i$ 的性质：</p>
<ul>
<li>幂等性：$A_i^2=A_i$</li>
<li>分离性：$A_i A_j=0(i\ne0)$</li>
<li>可加性：$\sum_{i=1}^n A_i = E_n$</li>
</ul>
<blockquote>
<p><strong>Remarks</strong></p>
<p>这里的幂等矩阵 $A_i$ 可以看作是正交<strong>基</strong>的概念</p>
<p>由前面投影矩阵的定义可知，<strong>每一个 $A_i$ 都是一个投影矩阵</strong>，将任意一个向量 $x$ 投影到 $v_i$ 张成的子空间 $L(v_i)$ 上。因此上面的幂等矩阵分解实际上可以理解为“<strong>特征空间分解</strong>”（笔者瞎想的名词），如何理解呢？把<strong>每个 $A_i$ 看作是矩阵 $A$ 的一个特征子空间（的投影基）</strong>，$Ax$ 实际上就是把 $x$ 投影到各个特征子空间中，然后根据对应的<strong>特征值</strong>进行伸缩，最后再合成一个作用后的向量，即表示 $A$ 对 $x$ 的线性变换。</p>
</blockquote>
<p><strong>定理</strong>：设 $A\in C^{n\times n}$，有 $k$ 个相异的特征值 $\lambda_i(i=1,…,k)$，则 $A$ 是<strong>单纯矩阵</strong>的充要条件是，存在 $k$ 个矩阵矩阵 $A_i$ 满足</p>
<ol>
<li>$A_{i} A_{j}=\left\{\begin{array}{ll}{A_{i}} &amp; {i=j} \\ {0} &amp; {i \neq j}\end{array}\right.$</li>
<li>$\sum_{i=1}^k A_i = E_n$</li>
<li>$A = \sum_{i=1}^k \lambda_i A_i$</li>
</ol>
</blockquote>
<ul>
<li><strong>正规矩阵</strong>：满足 $A^HA=AA^H$ 的矩阵<br><img src="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/normal%20matrix.jpg" srcset="/img/loading.gif" alt="正规矩阵"></li>
</ul>
<blockquote>
<p><strong>引理</strong>：设 $A$ 为正规矩阵，$A$ 与 $B$ <strong>酉相似</strong>，则 $B$ 为正规矩阵</p>
<blockquote>
<p> <strong>定理</strong>：任意矩阵 $A\in C^{n\times n}$，存在酉矩阵 $U$ 使得</p>
<script type="math/tex; mode=display">
A=URU^H \notag</script><p>其中 $R$ 为<strong>上三角矩阵</strong>且主对角线元素为 $A$ 的特征值</p>
</blockquote>
<p><strong>引理</strong>：设 $A$ 为正规矩阵且为三角矩阵，则 $A$ 为对角矩阵</p>
<blockquote>
<p><strong>Remarks</strong>：</p>
<p><strong>任意矩阵 $A$ 都与三角阵 $R$ 酉相似</strong>，因此若矩阵 $A$ 为正规阵，则 $R$ 既是正规阵，又是三角阵，则一定是对角阵。</p>
<p>因此，<strong>正规阵一定可以对角化</strong>，由下面的定理可知，可以<strong>酉对角化</strong>的矩阵一定是正规矩阵。</p>
<p>这与普通的可对角化矩阵的区别是什么呢？普通矩阵可对角化的充要条件是代数重数等于几何重数，也即只需要 <strong>n 个线性无关的特征向量</strong>即可($A=PJP^{-1}$)。而正规矩阵则要求<strong>所有特征向量正交</strong>($A=U\Lambda U^H$)！</p>
<p><strong>Remarks</strong></p>
<p>那么<strong>正定矩阵</strong>与<strong>正规矩阵</strong>的区别是什么呢？先看正定矩阵的定义：特征值全部为正数。区别很明显了，一个是从特征值角度，另一个是从特征向量角度，牢记这一点就不会弄混两者了。</p>
<p>凡是具有 $A^HA$ 形式的矩阵，既是<strong>正规矩阵</strong>，又是<strong>正定矩阵</strong>！</p>
</blockquote>
<p><strong>定理</strong>：$A$ 为正规矩阵的充要条件是存在酉矩阵 $U$ 使</p>
<script type="math/tex; mode=display">
A = U \text{diag}(\lambda_1,...,\lambda_n)U^H \notag</script><p>其中 $\lambda_i$ 是 $A$ 的特征值</p>
<p><strong>定理</strong>：$A$ 有 $k$ 个相异特征值，则 $A$ 是正规矩阵的充要条件是存在 $k$ 个矩阵 $A_i$ 满足</p>
<ol>
<li>$A_{i} A_{j}=\left\{\begin{array}{ll}{A_{i}} &amp; {i=j} \\ {0} &amp; {i \neq j}\end{array}\right.$</li>
<li>$\sum_{i=1}^k A_i = E_n$</li>
<li>$A = \sum_{i=1}^k \lambda_i A_i$</li>
<li>$A_i^H = A_i(i=1,…,k)$</li>
</ol>
</blockquote>
<h3 id="8-3-最大秩分解"><a href="#8-3-最大秩分解" class="headerlink" title="8.3 最大秩分解"></a>8.3 最大秩分解</h3><ul>
<li><strong>定理</strong>：设 $A\in C^{m\times n}_r$，则存在矩阵 $B\in C^{m\times r}_r, D\in C^{r\times n}_r$，使得 $A=BD$<ul>
<li>注：可以理解为 $B$ 取出了 $r$ 线性无关的列向量，或者 $D$ 取出了 $r$ 个线性无关的行向量</li>
<li>$(B^HB)^{-1}B^HB=E_r$，可以用于求 $B$ 的左逆，$D$ 同理</li>
</ul>
</li>
</ul>
<h3 id="8-4-奇异值分解"><a href="#8-4-奇异值分解" class="headerlink" title="8.4 奇异值分解"></a>8.4 奇异值分解</h3><ul>
<li><strong>奇异值</strong>：设 $A\in C^{m\times n}_r$，$A^HA$ 的特征值为 $\lambda_{1} \geq \lambda_{2} \geq \cdots \geq \lambda_{r}&gt;\lambda_{r+1}=\cdots=\lambda_{n}=\mathbf{0}$，则称 $\sigma_{i}=\sqrt{\lambda_{i}}(i=1,2, \cdots, r)$ 为 $A$ 的正奇异值（实际上就相当于 A 的“绝对特征值”）</li>
<li><strong>定理</strong>：设 $A\in C^{m\times n}_r$，则有<ol>
<li>$rank(A)=rank(A^HA)=rank(AA^H)$</li>
<li>$A^HA,AA^H$ 的特征值均为非负实数</li>
<li>$A^HA,AA^H$ 的特征值相同</li>
</ol>
</li>
<li><strong>酉等价</strong>：$A,B\in C^{m\times n}$，存在酉矩阵 $U,V$ 使得 $A=UBV$</li>
<li><strong>定理</strong>：若 $A,B$ 酉等价，则它们有相同的奇异值</li>
</ul>
<blockquote>
<p><strong>定理</strong>：设 $A\in C^{m\times n}_r$，$\sigma_1,…,\sigma_r$ 是 $A$ 的 $r$ 个奇异值，则存在酉矩阵 $U\in C^{m\times m},V\in C{n\times n}$，使得</p>
<script type="math/tex; mode=display">
A=U\left[\begin{array}{ll}{D} & {0} \\ {0} & {0}\end{array}\right] V \notag</script><p>其中 $\boldsymbol{D}=\operatorname{diag}\left(\delta_{1}, \delta_{2}, \cdots, \delta_{r}\right),\left|\delta_{i}\right|=\sigma_{i}$</p>
</blockquote>
<hr>
<h2 id="9-特征值估计"><a href="#9-特征值估计" class="headerlink" title="9. 特征值估计"></a>9. 特征值估计</h2><h3 id="9-1-几个不等式"><a href="#9-1-几个不等式" class="headerlink" title="9.1 几个不等式"></a>9.1 几个不等式</h3><ul>
<li><strong>定理 1(Schur 不等式)</strong>：设 $A\in C^{n\times n}$ 的特征值为 $\lambda_1,…,\lambda_n$，则 $\sum_{i=1}^{n}\left|\lambda_{i}\right|^{2} \leq \sum_{i=1}^{n} \sum_{j=1}^{n}\left|a_{i j}\right|^{2}=|A|_{F}^{2}$，等号成立当且仅当 $A$ 为正规矩阵</li>
<li><strong>定理 2(Hirsch)</strong>：设 $A\in C^{n\times n}$，记 $B=\frac{A+A^H}{2},C=\frac{A-A^H}{2}$，$A,B,C$ 特征值分别为 $\{\lambda_i\},\{\mu_i\},\{i\gamma_i\}$，均从大到小排列。则有<ol>
<li>$\left|\lambda_{i}\right| \leq n \max _{i, j}\left|a_{i j}\right|$</li>
<li>$\left|\mathbf{R e} \lambda_{i}\right| \leq n \max _{i, j}\left|b_{i j}\right|$</li>
<li>$\left|\mathbf{I m} \lambda_{i}\right| \leq \boldsymbol{n} \max _{i, j}\left|\boldsymbol{c}_{i j}\right|$</li>
</ol>
</li>
<li><strong>定理 3(Bendixson)</strong>：设 $A\in R^{n\times n}$，则 $A$ 的任一特征值满足 $\left|\mathbf{I m} \lambda_{i}\right| \leq \sqrt{\frac{n(n-1)}{2}} \max _{i, j}\left|c_{i j}\right|$</li>
</ul>
<h3 id="9-2-盖尔圆盘定理"><a href="#9-2-盖尔圆盘定理" class="headerlink" title="9.2 盖尔圆盘定理"></a>9.2 盖尔圆盘定理</h3><ul>
<li><strong>定义 1</strong>：设 $A\in C^{n\times n}$<ul>
<li>行盖尔圆盘：$S_{i}=\left\{z \in C:\left|z-a_{i i}\right| \leq R_{i}=\sum_{j \neq i}\left|a_{i j}\right|\right\}$</li>
<li>列盖尔圆盘：$G_{i}=\left\{z \in C:\left|z-a_{i i}\right| \leq C_{i}=\sum_{j \neq i}\left|a_{j i}\right|\right\}$</li>
</ul>
</li>
</ul>
<blockquote>
<p><strong>定理 1(圆盘定理)</strong>：设 $A\in C^{n\times n}$，则 $A$ 的任一特征值</p>
<script type="math/tex; mode=display">
\lambda_{i} \in \boldsymbol{S}=\bigcup_{j=1}^{n} \boldsymbol{S}_{j} \quad(\boldsymbol{i}=\mathbf{1}, 2, \cdots, \boldsymbol{n}) \notag</script><p>类似的，有</p>
<script type="math/tex; mode=display">
\lambda_{i} \in \left(\bigcup_{j=1}^{n} \boldsymbol{S}_{j}\right) \bigcap \left(\bigcup_{j=1}^{n} \boldsymbol{G}_{j}\right)
\quad(\boldsymbol{i}=\mathbf{1}, 2, \cdots, \boldsymbol{n}) \notag</script><p><strong>定理 2</strong>：设 $n$ 阶方阵 $A$ 的 $n$ 个盖尔圆盘中有 $k$ 个圆盘的并形成一个<strong>连通区域</strong> $G$（圆盘相切也算连通），且它与余下的 $n-k$ 个圆盘都不相交，则在该区域中恰好有 $A$ 的 $k$ 个特征值</p>
<p><strong>证明</strong>：取 $A_{\varepsilon}=D+\varepsilon B,\ \varepsilon \in[0,1]$，而 $A_\varepsilon$ 的特征值 $\lambda_i(A_\varepsilon) = \lambda_i(\varepsilon)$ 时关于 $\varepsilon$ 的<strong>连续函数</strong>，在圆盘随着 $\varepsilon$ 扩大过程中，特征值一直都处于圆盘内部</p>
<p><img src="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/gerschgorin.jpg" srcset="/img/loading.gif" alt="gerschgorin"></p>
<p><strong>推论 1</strong>：设 $n$ 阶方阵 $A$ 的 $n$ 个盖尔圆盘两两互不相交，则 $A$ 相似于对角阵</p>
<p><strong>推论 2</strong>：设 $n$ 阶<strong>实矩阵</strong> $A$ 的 $n$ 个盖尔圆盘两两互不相交，则 $A$ 的特征值全部为实数</p>
<p><strong>改进</strong>：可以取 $D=diag(p_1,…,p_n),\ \ p_i&gt;0$，则有 $D^{-1}AD$ 与 $A$ <strong>相似</strong>，因此他们有相同的特征值，可以用 $D^{-1}AD$ 的特征值来估计 $A$。此时可以将某些盖尔圆变小，但是代价就是其他盖尔圆会变大。</p>
</blockquote>
<ul>
<li><strong>行对角占优</strong>：$\left|a_{ii}\right| \geq R_{i}=\sum_{j=1, j \ne i}^{n}\left|a_{i j}\right| \quad(i=1,2, \cdots, n)$</li>
<li><strong>列对角占优</strong>：$\left|a_{ii}\right| \geq C_{i}=\sum_{j=1, j \ne i}^{n}\left|a_{ji}\right| \quad(i=1,2, \cdots, n)$</li>
</ul>
<blockquote>
<p><strong>定理 3</strong>：设 $A\in C^{n\times n}$ <strong>严格</strong>行对角占优，则</p>
<ol>
<li>$A$ 可逆</li>
<li>若 $A$ 所有主对角元都为正数，则 $A$ 的特征值都有正实部</li>
<li>若 $A$ 为 Hermite 矩阵，且所有主对角元都为正数，则 $A$ 的特征值都为正数</li>
</ol>
</blockquote>
<h3 id="9-3-Hermite矩阵特征值的变分特性"><a href="#9-3-Hermite矩阵特征值的变分特性" class="headerlink" title="9.3 Hermite矩阵特征值的变分特性"></a>9.3 Hermite矩阵特征值的变分特性</h3><p>因为Hermite矩阵 $A\in C^{n\times n}$ 的特征值均为实数，所以可以把他们记作（按照大小进行排序）：</p>
<script type="math/tex; mode=display">
\lambda_{\min }=\lambda_{n} \leq \lambda_{n-1} \ldots \leq \lambda_{2} \leq \lambda_{1}=\lambda_{\max } \notag</script><ul>
<li><strong>Rayleigh 商</strong>：$R(x)=\frac{x^{H} A x}{x^{H} x} \quad x \neq 0$<ul>
<li>$\lambda_{n} x^{H} x \leq x^{H} A x \leq \lambda_{1} x^{H} x \quad\left(\forall x \in C^{n}\right)$</li>
<li>$\lambda_{\max }=\lambda_{1}=\max _{x \neq 0} R(x)=\max _{x^{H}} x^{H} A x$</li>
<li>$\lambda_{\min }=\lambda_{n}=\min _{x \neq 0} R(x)=\min _{x^{H} x=1} x^{H} A x$</li>
</ul>
</li>
<li><strong>定理(Courant-Fischer)</strong>：设特征值 $\lambda_1 \le \lambda_2 \le \cdots \le \lambda_n$，则<ul>
<li>$\begin{array}{ccc}{\min } &amp; {\max } &amp; {R(x)=\lambda_{k}} \\ {\omega_{1}, \omega_{2}, \cdots, \omega_{n-k} \in C^{n}} &amp; {x \neq 0, x \in C^{n} \atop {x \perp \omega_{1}, \omega_{2}, \cdots, \omega_{n-k}}} &amp; {} \end{array}$</li>
<li>$\begin{array}{ccc}{\max } &amp; {\min } &amp; {R(x)=\lambda_{k}} \\ {\omega_{1}, \omega_{2}, \cdots, \omega_{n-k} \in C^{n}} &amp; {x \neq 0, x \in C^{n} \atop {x \perp \omega_{1}, \omega_{2}, \cdots, \omega_{n-k}}} &amp; {} \end{array}$</li>
</ul>
</li>
<li><strong>定理(Weyl)</strong>：$\lambda_k(A)+\lambda_n(B)\le\lambda_k(A+B)\le\lambda_k(A)+\lambda_1(B)$</li>
</ul>
<hr>
<h2 id="10-矩阵分析"><a href="#10-矩阵分析" class="headerlink" title="10. 矩阵分析"></a>10. 矩阵分析</h2><h3 id="10-1-矩阵序列与矩阵级数"><a href="#10-1-矩阵序列与矩阵级数" class="headerlink" title="10.1 矩阵序列与矩阵级数"></a>10.1 矩阵序列与矩阵级数</h3><ul>
<li>矩阵序列<ul>
<li><strong>定理</strong>：设 $\Vert\cdot\Vert$ 是 $C^{m\times n}$ 上的任一矩阵范数，矩阵序列 $\{A^{(k)}\}$ 收敛于 $A$ 的充要条件是 $\lim _{k \rightarrow+\infty}\left|A^{(k)}-A\right|=0$</li>
<li><strong>定理</strong>：设 $\lim _{k \rightarrow+\infty} A^{(k)}=A, \lim _{k \rightarrow+\infty} B^{(k)}=B . \alpha, \beta \in C$，则<ul>
<li>$\lim _{k \rightarrow+\infty}\left(\alpha A^{(k)}+\beta B^{(k)}\right)=\alpha A+\beta B$</li>
<li>$\lim _{k \rightarrow+\infty} A^{(k)} B^{(k)}=A B$</li>
<li>当 $A^{(k)}$ 与 $A$ 都可逆时，$\lim _{k \rightarrow+\infty}\left(A^{(k)}\right)^{-1}=A^{-1}$</li>
</ul>
</li>
</ul>
</li>
<li><strong>收敛矩阵</strong>：设 $A\in C^{n\times n}$，若 $\lim _{k \rightarrow \infty} A^{k}=0$，则称 $A$ 为收敛矩阵<ul>
<li><strong>定理</strong>：设 $A\in C^{n\times n}$，则 $A$ 为收敛矩阵的充要条件是 $r(A)&lt;1$</li>
</ul>
</li>
<li><strong>矩阵级数</strong>：$\sum_{k=1}^{\infty} A^{(k)}=A^{(1)}+A^{(2)}+\cdots+A^{(k)}+\cdots$，称 $\boldsymbol{S}^{(\boldsymbol{N})}=\sum_{\boldsymbol{k}=1}^{\boldsymbol{N}} \boldsymbol{A}^{(\boldsymbol{k})}$ 为矩阵级数的部分和，若 $\lim _{N \rightarrow \infty} S^{(N)}=S$ 则称级数<strong>收敛</strong><ul>
<li><strong>定理</strong>：在 $C^{n\times n}$ 中，$\sum_{k=1}^{\infty} A^{(k)}$ 绝对收敛的充要条件是正项级数 $\sum_{k=1}^{\infty}\left|A^{(k)}\right|$ 收敛</li>
<li><strong>定理</strong>：方阵 $A$ 的 Neumann 级数 $\sum_{k=0}^{\infty} A^{k}=I+A+A^{2}+\cdots+A^{k}+\cdots$ 收敛的充要条件是 $r(A)&lt;1$，且收敛时，其和为 $(I-A)^{-1}$</li>
</ul>
</li>
</ul>
<h3 id="10-2-矩阵函数"><a href="#10-2-矩阵函数" class="headerlink" title="10.2 矩阵函数"></a>10.2 矩阵函数</h3><ul>
<li><p>幂级数：设幂级数 $\sum_{k=0}^{\infty} c_{k} z^{k}$ 收敛半径为 $r$，且当 $|z|&lt;r$ 时，幂级数收敛于函数 $f(z)$，即 $f(z)=\sum_{k=0}^{\infty} c_{k} z^{k}, \quad|z|&lt;r$</p>
</li>
<li><p>矩阵幂级数：如果 $A\in C^{n\times n}$ 满足 $r(A)&lt;r$，则称收敛矩阵的矩阵幂级数 $\sum_{k=0}^{\infty} a_{k} A^{k}$ 为矩阵函数，记为 $f(A)$，即 $f(A)=\sum_{k=0}^{\infty} c_{k} A^{k}$，考虑参数 $t$，有 $f(At)=\sum_{k=0}^{\infty} c_{k} (At)^{k}$</p>
<ul>
<li>常用矩阵函数：</li>
<li>$e^{A}=\sum_{k=0}^{\infty} \frac{1}{k !} A^{k}, \quad A \in C^{n \times n}$</li>
<li>$\sin A=\sum_{k=0}^{\infty} \frac{(-1)^{k}}{(2 k+1) !} A^{2 k+1}, \quad A \in C^{n \times n}$</li>
<li>$\cos A=\sum_{k=0}^{\infty} \frac{(-1)^{k}}{(2 k) !} A^{2 k}, \quad A \in C^{n \times n}$</li>
<li>$(E-A)^{-1}=\sum_{k=0}^{\infty} A^{k}, \quad r(A)&lt;1$</li>
<li>$\ln (E+A)=\sum_{k=0}^{\infty} \frac{(-1)^{k}}{k+1} A^{k+1}, \quad r(A)&lt;1$</li>
</ul>
</li>
<li><p>矩阵函数值计算</p>
<ul>
<li><p>相似对角化：设 $P^{-1}AP=diag(\lambda_1,…,\lambda_n)=D$，则 $f(At) = P\cdot diag(f(\lambda_1 t),…,f(\lambda_n t))\cdot P^{-1}$</p>
</li>
<li><p>Jordan标准型：设 $P^{-1}AP=diag(J_1,…,J_s)$，则 </p>
<script type="math/tex; mode=display">
f(A)=P\left(\begin{array}{ccc}
{f\left(J_{1}\right)} & {} & {} \\
{} & {\ddots} & {} \\
{} & {} & {f\left(J_{s}\right)}
\end{array}\right) P^{-1} \notag</script></li>
</ul>
</li>
<li><p>矩阵函数性质</p>
<ul>
<li>如果 $AB=BA$，则<ul>
<li>$e^{A} e^{B}=e^{B} e^{A}=e^{A+B}$</li>
<li>$\cos (A+B)=\cos A \cos B-\sin A \sin B$</li>
<li>$\sin (A+B)=\sin A \cos B+\cos A \sin B$</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h2 id="11-矩阵求逆"><a href="#11-矩阵求逆" class="headerlink" title="11 矩阵求逆"></a>11 矩阵求逆</h2><hr>
<h2 id="Hermite矩阵的性质"><a href="#Hermite矩阵的性质" class="headerlink" title="Hermite矩阵的性质"></a>Hermite矩阵的性质</h2><ul>
<li>一般 Hermite 矩阵<ul>
<li>Hermite 矩阵本身就是<strong>正规矩阵</strong>，因此可以对角化(几何重数等于代数重数)，不同特征向量<strong>正交</strong></li>
<li>特征值均为<strong>实数</strong>（反 Hermite 矩阵的特征值全为虚数）</li>
</ul>
</li>
<li>正定 Hermite 矩阵<ul>
<li>主对角线元素全部大于 0</li>
<li>存在正定 Hermite 矩阵 $B$ 使得 $A=B^2$（可以无穷分解）</li>
<li>$A$ 的任意 k 行和对应的 k 列组成的主子阵是正定的 </li>
</ul>
</li>
</ul>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/Linear-Algebra/">Linear Algebra</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/">线性代数</a>
                    
                      <a class="hover-with-bg" href="/tags/%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90/">矩阵分析</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2020/02/09/tools/laptop/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">笔记本选购指南</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2020/02/03/statistic/SI_Ch11_Sumproduct/">
                        <span class="hidden-mobile">统计推断(十一)  Sum-product algorithm</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments">
                
                
  <div id="vcomments"></div>
  <script type="text/javascript">
    Fluid.utils.waitElementVisible('vcomments', function() {
      Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js', function () {
        new Valine({
          el: "#vcomments",
          app_id: "iw199srhJNXO53sMUbMWkSxL-gzGzoHsz",
          app_key: "ogmo6qYs8PSc7MBFk8A1PDUl",
          placeholder: "说点啥子吧 ^_^",
          path: window.location.pathname,
          avatar: "retro",
          meta: ["nick","mail","link"],
          pageSize: "10",
          lang: "zh-CN",
          highlight: false,
          recordIP: false,
          serverURLs: "",
        });
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the
    <a href="https://valine.js.org" rel="nofollow noopener">comments powered by Valine.</a>
  </noscript>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


  

  
</footer>

<!-- SCRIPTS -->

  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.0/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.0/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    (function () {
      var path = "/local-search.xml";
      var inputArea = document.querySelector("#local-search-input");
      inputArea.onclick = function () {
        searchFunc(path, 'local-search-input', 'local-search-result');
        this.onclick = null
      }
    })()
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-svg.js" ></script>

  











<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>



</body>
</html>
