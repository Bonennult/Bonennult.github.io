<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Gemini","version":"7.7.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="在网上自学矩阵分析的一些笔记，主要是总结一些结论性的东西，并没有太多证明。对于非数学专业的学生，笔者认为抛开证明的细节，从更加具象的角度理解矩阵可能会有更清晰的理解。 未完待续，更新中 … 参考资料：知乎专栏">
<meta name="keywords" content="线性代数,矩阵分析">
<meta property="og:type" content="article">
<meta property="og:title" content="矩阵分析学习笔记">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2020&#x2F;02&#x2F;03&#x2F;linear-algebra&#x2F;matrix&#x2F;index.html">
<meta property="og:site_name" content="你是下雨天">
<meta property="og:description" content="在网上自学矩阵分析的一些笔记，主要是总结一些结论性的东西，并没有太多证明。对于非数学专业的学生，笔者认为抛开证明的细节，从更加具象的角度理解矩阵可能会有更清晰的理解。 未完待续，更新中 … 参考资料：知乎专栏">
<meta property="og:locale" content="en">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Glooow1024&#x2F;ImgHosting&#x2F;master&#x2F;hexo&#x2F;2019&#x2F;proj.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Glooow1024&#x2F;ImgHosting&#x2F;master&#x2F;hexo&#x2F;2019&#x2F;decom.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Glooow1024&#x2F;ImgHosting&#x2F;master&#x2F;hexo&#x2F;2019&#x2F;norm%20equality.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Glooow1024&#x2F;ImgHosting&#x2F;master&#x2F;hexo&#x2F;2019&#x2F;normal%20matrix.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Glooow1024&#x2F;ImgHosting&#x2F;master&#x2F;hexo&#x2F;2020&#x2F;gerschgorin.jpg">
<meta property="og:updated_time" content="2020-03-27T10:11:28.157Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Glooow1024&#x2F;ImgHosting&#x2F;master&#x2F;hexo&#x2F;2019&#x2F;proj.jpg">

<link rel="canonical" href="http://yoursite.com/2020/02/03/linear-algebra/matrix/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true
  };
</script>

  <title>矩阵分析学习笔记 | 你是下雨天</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">你是下雨天</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="search-pop-overlay">
  <div class="popup search-popup">
      <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

  </div>
</div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/03/linear-algebra/matrix/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Glooow">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="你是下雨天">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          矩阵分析学习笔记
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-02-03 21:08:25" itemprop="dateCreated datePublished" datetime="2020-02-03T21:08:25+08:00">2020-02-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-03-27 18:11:28" itemprop="dateModified" datetime="2020-03-27T18:11:28+08:00">2020-03-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Linear-Algebra/" itemprop="url" rel="index"><span itemprop="name">Linear Algebra</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/02/03/linear-algebra/matrix/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/02/03/linear-algebra/matrix/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>在网上自学矩阵分析的一些笔记，主要是总结一些结论性的东西，并没有太多证明。对于非数学专业的学生，笔者认为抛开证明的细节，从更加具象的角度理解矩阵可能会有更清晰的理解。</p>
<p>未完待续，更新中 …</p>
<p>参考资料：<a href="https://zhuanlan.zhihu.com/matrix-learning" target="_blank" rel="noopener">知乎专栏</a></p>
<a id="more"></a>
<hr>
<h2 id="1-线性代数基础——空间"><a href="#1-线性代数基础——空间" class="headerlink" title="1. 线性代数基础——空间"></a>1. 线性代数基础——空间</h2><ul>
<li><p>几个基本的概念</p>
<ul>
<li><p><strong>数域</strong>：对<strong>加减乘除</strong>四则基本<strong>运算封闭</strong>的<strong>数集</strong></p>
<ul>
<li>注意：首先<strong>数域</strong>的概念针对的是<strong>数集</strong>，不是向量也不是矩阵；其次要求对四则基本运算封闭。</li>
</ul>
</li>
<li><p><strong>线性空间</strong>：需满足以下条件</p>
<script type="math/tex; mode=display">
\begin{alignat}{1}
&1)\ \alpha+\beta=\beta+\alpha     &5)\ 1 a=\alpha\notag\\
&2)\ (\alpha+\beta)+\gamma=\alpha+(\beta+\gamma)   &6)\ k(l \alpha)=(k l) \alpha\notag\\
&3)\ \exists 0 \in V, \forall \alpha \in V, 有 \alpha+0=\alpha &7)\ (k+l) \alpha=k \alpha+l \alpha\notag\\
&4)\ \forall \alpha \in V, \exists \beta \in V, s.t.\  \alpha+\beta=0 \qquad &8)\ k(\alpha+\beta)=k \alpha+l \beta\notag\\
\end{alignat}\notag</script></li>
<li><p><strong>子空间</strong>：</p>
</li>
<li><p>空间的<strong>维数</strong>：基的个数</p>
</li>
<li><p><strong>平凡子空间</strong>：V 空间的子空间只有 0 空间和 V 空间本身</p>
</li>
<li><p><strong>非平凡子空间</strong>：除了平凡子空间，其他所有子空间</p>
</li>
<li><p>子空间的<strong>直和</strong>：$V_1 \cap V_2=\{0\}$ 时，直和可定义为 $V_1 \bigoplus V_2$，主要是为了保证<strong>分解的唯一性</strong>。可以推广到多个子空间 $V_i (\sum_{j\ne i}V_j) = \{0\}$</p>
<ul>
<li>注：$V_1,V_2$ 相互可能不是正交的，比如二维平面中不正交的两个基</li>
</ul>
</li>
<li><p><strong>酉空间</strong>：欧几里得空间推广到<strong>复数域</strong></p>
</li>
</ul>
</li>
</ul>
<hr>
<h2 id="2-投影"><a href="#2-投影" class="headerlink" title="2. 投影"></a>2. 投影</h2><ul>
<li><strong>变换</strong>：线性空间到自身的映射 $T:V(C)\to V(C)$</li>
<li><strong>线性变换</strong>：<ul>
<li>$T(\alpha+\beta) = T(\alpha)+T(\beta)$</li>
<li>$T(k\alpha) = kT(\alpha)$</li>
</ul>
</li>
<li><strong>投影</strong>：$T$ 是 $V(C)$ 上的投影， $\iff T^2=T$</li>
</ul>
<blockquote>
<p><strong>定理 1</strong>：设 $T$ 是 $V(C)$ 上的投影，则 $V(C) = R(T)\bigoplus N(T)$</p>
<p><strong>定理 2</strong>：设 $V(C) = V_1\bigoplus V_2$，则存在投影 $T$ 使得 $R(T)=V_1, N(T)=V_2$</p>
<p><strong>Remark</strong>：根据投影的定义 $T^2=T$，可以形象理解为<strong>降维</strong>操作，也即投影过程不可逆，投影一次后即进入<strong>值域</strong> $R(T)$，也即是 $V(C)$ 的一个低维子空间。</p>
</blockquote>
<ul>
<li><p><strong>投影矩阵</strong>：投影 $T$ 为线性变换，可以用矩阵 $A$ 表示<br><img src="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/proj.jpg" alt="线性变换"></p>
</li>
<li><p><strong>幂等矩阵</strong>：满足 $A^2=A$，有如下性质</p>
<ul>
<li>$A^H$ 与 $(E-A)$ 也是幂等矩阵</li>
<li>$A$ 的特征值只有 0 和 1，且可以对角化</li>
<li>$rank(A)=tr(A)$</li>
<li>$A(E-A)=(E-A)A$</li>
<li>$Aa = a, \iff a\in R(A)$</li>
<li>$N(A)=R(E-A), R(A)=N(E-A)$</li>
</ul>
<blockquote>
<p>上面的性质均可由<strong>幂等矩阵</strong>的性质导出</p>
</blockquote>
</li>
<li><p><strong>正交投影</strong>：$\iff R^{\perp}(T) = N(T) \iff A^H=A$</p>
</li>
</ul>
<blockquote>
<p><strong>Remark</strong>：</p>
<ul>
<li>实际上对于正交投影 $A$，可以写成以下形式</li>
</ul>
<p><img src="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/decom.jpg" alt="正交投影分解"></p>
<ul>
<li>是否存在<strong>非正交投影</strong>呢？非正交投影又是什么形式呢？<br>只需要将中间的对角阵换成Jordan标准型的形式？</li>
</ul>
</blockquote>
<hr>
<h2 id="3-Jordan标准型"><a href="#3-Jordan标准型" class="headerlink" title="3. Jordan标准型"></a>3. Jordan标准型</h2><p>注：此部分是矩阵论的基本定理之一，非常重要！！！</p>
<blockquote>
<p><strong>定理 1</strong>：任意 n 阶矩阵 $A$，一定存在 n 阶<strong>可逆矩阵</strong> P 使得</p>
<script type="math/tex; mode=display">
P^{-1} A P=\left(\begin{array}{cccc}
{J_{1}} & {} & {} & {} \\
{} & {J_{2}} & {} & {} \\
{} & {} & {\ddots} & {} \\
{} & {} & {} & {J_{k}}
\end{array}\right)=J \notag</script><p>其中 $J_i$ 为 Jordan 块。有以下几个结论</p>
<ol>
<li>Jordan 块的个数是<strong>线性无关特征向量的个数</strong></li>
<li>矩阵可<strong>对角化</strong>当且仅当 $k=n$</li>
<li>对于某个特征值，Jordan 块个数为<strong>几何重数</strong>，所有 Jordan 块的阶数之和为<strong>代数重数</strong>（特征值多项式根的阶数即为代数重数，永远有几何重数不大于代数重数）</li>
<li>特征值的几何重数不大于代数重数</li>
<li>矩阵不同特征值对应的<strong>特征向量线性无关</strong></li>
</ol>
</blockquote>
<hr>
<h2 id="4-初等矩阵与酉矩阵"><a href="#4-初等矩阵与酉矩阵" class="headerlink" title="4. 初等矩阵与酉矩阵"></a>4. 初等矩阵与酉矩阵</h2><h3 id="4-1-初等变换矩阵"><a href="#4-1-初等变换矩阵" class="headerlink" title="4.1 初等变换矩阵"></a>4.1 初等变换矩阵</h3><blockquote>
<p><strong>定义</strong>：设 $\boldsymbol{u,v}\in \mathbb{C}^n,\sigma\in \mathbb{C}$，则称 $E(\boldsymbol{u,v},\sigma)=E-\sigma\boldsymbol{uv}^H$ 为<strong>初等变换矩阵</strong></p>
</blockquote>
<ul>
<li><p><strong>初等变换</strong>矩阵性质</p>
<ul>
<li>特征向量<ul>
<li>若 $\boldsymbol{u\in v^{\perp}}$，设 $\boldsymbol{u_1,…,u_{n-1}}$ 是 $v^\perp$ 的一组基，则 $E(\boldsymbol{u,v},\sigma)$ 的一组<strong>线性无关</strong>的特征向量为 $\boldsymbol{u_1,…,u_{n-1}}$</li>
<li>若 $\boldsymbol{u\notin v^{\perp}}$，设 $\boldsymbol{u_1,…,u_{n-1}}$ 是 $v^\perp$ 的一组基，则 $E(\boldsymbol{u,v},\sigma)$ 的一组<strong>线性无关</strong>的特征向量为 $\boldsymbol{u,u_1,…,u_{n-1}}$</li>
</ul>
</li>
<li>特征值 $\lambda(E(\boldsymbol{u,v},\sigma))=\{1,…,1,1-\sigma v^H u\}$</li>
<li>行列式 $det(E(\boldsymbol{u,v},\sigma))=1-\sigma v^H u$</li>
<li>逆矩阵 $E(u, v, \sigma)^{-1}=E\left(u, v, \frac{\sigma}{\sigma v^{H} u-1}\right),\left(1-\sigma v^{H} u \neq 0\right)$</li>
<li>非零向量 $\boldsymbol{a,b}\in\mathbb{C}^n$，存在 $\boldsymbol{u,v},\sigma$ 使得 $E(u, v, \sigma) a=b,\left(\sigma u=\frac{a-b}{v^{H} a}\right)$</li>
</ul>
<blockquote>
<p><strong>Remarks</strong></p>
<ol>
<li>前两个性质可以根据 $u,v$ 的垂直关系直观想象。当 $u\perp v$ 时，此时 $E$ 对于特征值 $1$ 的代数重数为 $n$，而几何重数为 $n-1$（注意此时出现了代数重数大于几何重数的情况！）；否则，$E$ 对于特征值 $1$ 的代数重数和几何重数为 $n-1$，且有另一个特征值 $1-\sigma v^H u$</li>
</ol>
</blockquote>
</li>
<li><p>所有初等变换可以用上述定义表示</p>
<ul>
<li>置换 ${E_{i j}=E-\left(e_{i}-e_{j}\right)\left(e_{i}-e_{j}\right)^{T}=E\left(e_{i}-e_{j}, e_{i}-e_{j}, 1\right)}$</li>
<li>相消 ${E_{i j}(k)=E+k e_{j} e_{i}^{T}=E\left(e_{j}, e_{i},-k\right)}$</li>
<li>数乘 ${E_{i}(k)=E-(1-k) e_{i} e_{i}^{T}=E\left(e_{i}, e_{i}, 1-k\right)}$</li>
</ul>
</li>
</ul>
<h3 id="4-2-初等酉矩阵"><a href="#4-2-初等酉矩阵" class="headerlink" title="4.2 初等酉矩阵"></a>4.2 初等酉矩阵</h3><blockquote>
<p><strong>定义</strong>：设 $\boldsymbol{u}\in \mathbb{C}^n$ 且 $u^H u =1$，则称 $H(U)=E(\boldsymbol{u,U},2)=E-2\boldsymbol{uu}^H$ 为<strong>初等酉矩阵</strong>，或者<strong>Householder矩阵</strong></p>
</blockquote>
<ul>
<li><strong>Householder</strong>变换性质<ul>
<li>$H^H=H=H^{-1}$</li>
<li>$H(\boldsymbol{u})(\boldsymbol{a}+r\boldsymbol{u})=\boldsymbol{a}-r\boldsymbol{u}, \forall a\in v^\perp, r\in\mathbb{C}$（镜像变换）</li>
<li>范数不变性：$||Hx||=||x||$</li>
<li>保持随机向量的协方差</li>
<li>可用于数值算法构造正交基</li>
</ul>
</li>
</ul>
<h3 id="4-3-酉变换"><a href="#4-3-酉变换" class="headerlink" title="4.3 酉变换"></a>4.3 酉变换</h3><ul>
<li><strong>酉变换与酉矩阵</strong><ol>
<li>保持<strong>内积</strong>不变</li>
<li>保持长度不变</li>
<li>保持夹角不变</li>
<li>保持形状不变</li>
</ol>
</li>
<li>内积的定义，比如连续区间中对连续函数的定义</li>
</ul>
<hr>
<h2 id="5-欧氏空间中的度量（？）"><a href="#5-欧氏空间中的度量（？）" class="headerlink" title="5. 欧氏空间中的度量（？）"></a>5. 欧氏空间中的度量（？）</h2><ul>
<li><p><strong>内积</strong>：满足 4 条性质</p>
<ol>
<li>$(x,x)\ge0,且(x,x)=0\iff x=0$</li>
<li>$(x,y)=\overline{(y,x)},\forall x,y\in V(P)$</li>
<li>$(\lambda x,y)=\bar{\lambda}(x,y),\forall \lambda\in P,\forall x,y\in V(P)$</li>
<li>$(x+y,z)=(x,z)+(y,z),\forall x,y,z\in V(P)$</li>
</ol>
</li>
<li><p><strong>线性流形</strong>：$P=r_{0}+V_{1}=\left\{r_{0}+\alpha | \alpha \in V_{1}\right\}$</p>
<ul>
<li>实际上就是将子空间进行平移</li>
</ul>
</li>
<li><p>n 维空间中的<strong>体积</strong></p>
<ol>
<li>$V(\alpha_1)=||\alpha_1||$</li>
<li>$V\left(\alpha_{1}, \alpha_{2}, \cdots, \alpha_{n}\right)=V\left(\alpha_{1}, \alpha_{2}, \cdots, \alpha_{n-1}\right) \bullet h_{n}$，其中 $h_n$ 是 $\alpha_n$ 到 $L(\alpha_{1}, \alpha_{2}, \cdots, \alpha_{n-1})$ 的距离</li>
</ol>
</li>
<li><p>Gram 行列式</p>
<script type="math/tex; mode=display">
G\left(\alpha_{1}, \cdots, \alpha_{k}\right)=\left| \begin{array}{cccc}
{\left(\alpha_{1}, \alpha_{1}\right)} & {\left(\alpha_{1}, \alpha_{2}\right)} & {\cdots} & {\left(\alpha_{1}, \alpha_{k}\right)} \\
{\left(\alpha_{2}, \alpha_{1}\right)} & {\left(\alpha_{2}, \alpha_{2}\right)} & {\cdots} & {\left(\alpha_{2}, \alpha_{k}\right)} \\
{\cdots} & {\cdots} & {\cdots} & {\cdots} \\
{\left(\alpha_{k}, \alpha_{1}\right)} & {\left(\alpha_{k}, \alpha_{2}\right)} & {\cdots} & {\left(\alpha_{k}, \alpha_{k}\right)}
\end{array}\right|\notag</script></li>
<li><p>将线性无关向量组 $\alpha_{1}, \alpha_{2}, \cdots, \alpha_{n}$ 正交化之后，Gram 行列式不变，即 $G\left(\alpha_{1}, \alpha_{2}, \cdots, \alpha_{k}\right)=G\left(\beta_{1}, \beta_{2}, \cdots, \beta_{k}\right)$</p>
</li>
<li><p>体积 $V\left(\alpha_{1}, \alpha_{2}, \cdots, \alpha_{n}\right)=\sqrt{G\left(\alpha_{1}, \alpha_{2}, \cdots, \alpha_{n}\right)}$</p>
</li>
<li><p>定理 1：设 $\alpha_{1}, \alpha_{2}, \cdots, \alpha_{k}$ 是 $V_1$ 的一组基，向量 $\alpha$ 到流形 $P=\alpha_0+V_1$ 的距离为 $d^{2}=\frac{G\left(\alpha_{1}, \cdots, \alpha_{k}, \alpha-\alpha_{0}\right)}{G\left(\alpha_{1}, \cdots, \alpha_{k},\right)}$</p>
</li>
<li><p>定理 2：线性流形 $P_1=\alpha_0+V_1$ 和 $P_2=\alpha_0+V_1$ 之间的距离等于 $\alpha_1-\alpha_2$ 关于线性子空间 $V=V_1+V_2$ 的正交分量长度</p>
</li>
</ul>
<hr>
<h2 id="6-Kronecker积"><a href="#6-Kronecker积" class="headerlink" title="6. Kronecker积"></a>6. Kronecker积</h2><ul>
<li>性质<ul>
<li>$E_m\bigotimes E_n = E_{mn}$</li>
<li></li>
</ul>
</li>
</ul>
<hr>
<h2 id="7-范数"><a href="#7-范数" class="headerlink" title="7. 范数"></a>7. 范数</h2><h3 id="7-1-向量范数"><a href="#7-1-向量范数" class="headerlink" title="7.1 向量范数"></a>7.1 向量范数</h3><ul>
<li>范数：刻画向量大小的度量，需要满足以下三条性质<ol>
<li>正定性：$||x||\ge0,且||x||=0\iff x=0$</li>
<li>齐次性：$||\lambda x||=|\lambda|\cdot ||x||,\lambda\in R,x\in C^n$</li>
<li>三角不等式：$||x+y||\le ||x||+||y||,\forall x,y\in C^n$</li>
</ol>
</li>
<li>范数与内积的关系是什么？</li>
<li>导出性质<ul>
<li>$||0||=0$</li>
<li>$x\ne0时,||\frac{1}{||x||}x||=1$</li>
<li>$||-x||=||x||,\forall x\in C^n$</li>
<li>$\vert \Vert x\Vert-\Vert y\Vert \vert \le \Vert x-y \Vert$</li>
</ul>
</li>
<li>常用范数<ul>
<li>1范数：$|x|_{1}=\sum_{i=1}^{n}\left|x_{i}\right|$</li>
<li>2范数：$|x|_{2}=\left(\sum_{i=1}^{n}\left|x_{i}\right|^{2}\right)^{1 / 2}$</li>
<li>$\infty$范数：$|x|_{\infty}=\max _{1 \leq i \leq n}\left|x_{i}\right|$</li>
<li>p范数(Holder范数)：$|x|_{p}=\left(\sum_{i=1}^{n}\left|x_{i}\right|^{p}\right)^{1 / p} \quad 1 \leq p&lt;\infty$<ul>
<li>p可取<strong>正整数</strong></li>
<li>可验证满足三角不等式，需要用到Young不等式和Holder不等式</li>
</ul>
</li>
</ul>
</li>
<li>向量序列的<strong>收敛性</strong></li>
<li>向量范数的<strong>等价性</strong><ul>
<li><img src="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/norm%20equality.jpg" alt="范数等价性"><br>等价性表示不同范数的量级是相同的，只差一个系数</li>
<li><strong>定理</strong>：$V(P)$ 上的任意两个向量范数均等价</li>
<li><strong>范数等价保证了向量序列的收敛性与范数选取无关</strong>。无穷范数收敛，其他范数一定收敛。其他范数收敛，无穷范数一定收敛。</li>
</ul>
</li>
</ul>
<h3 id="7-2-矩阵范数"><a href="#7-2-矩阵范数" class="headerlink" title="7.2 矩阵范数"></a>7.2 矩阵范数</h3><ul>
<li><p>矩阵可以转化为向量表示</p>
</li>
<li><p>矩阵范数：$A\in P^{m\times n}$，需满足以下条件</p>
<ol>
<li>正定性：$||A||\ge0,且||A||=0\iff A=0$</li>
<li>齐次性：$||\lambda A||=|\lambda|\cdot ||A||,\lambda\in R,A\in P^{m\times n}$</li>
<li>三角不等式：$||A+B||\le ||A||+||B||,\forall A,B\in P^{m\times n}$</li>
<li><strong>相容性</strong>：$\Vert AB \Vert \le \Vert A\Vert\cdot \Vert B\Vert$</li>
</ol>
<blockquote>
<p><strong>Remarks</strong>：这里相容性的定义目的是什么呢？为了放缩方便？</p>
</blockquote>
</li>
<li><p>例如</p>
<ul>
<li>（自相容）$|A|_{m_{1}}=\sum_{j=1}^{n} \sum_{i=1}^{m}\left|a_{i j}\right|$</li>
<li>（不相容）$|A|_{m_{\infty}}=\max _{i, j}\left\{\left|a_{i j}\right|\right\} \quad 1 \leq i \leq m \quad 1 \leq j \leq n$</li>
<li>（自相容）Frobenius范数：$|A|_{m_{2}}=\left(\sum_{j=1}^{n} \sum_{i=1}^{m}\left|a_{i j}\right|^{2}\right)^{\frac{1}{2}}$<ul>
<li>$|\boldsymbol{A}|_{m_{2}}^{2}=\operatorname{tr}\left(\boldsymbol{A}^{\boldsymbol{H}} \boldsymbol{A}\right)=\sum_{i=1}^{n} \lambda_{i}\left(\boldsymbol{A}^{\boldsymbol{H}} \boldsymbol{A}\right)$</li>
<li>对任意酉矩阵$U,V$，$|\boldsymbol{A}|_{m_{2}}^{2}=\left|\boldsymbol{U}^{\boldsymbol{H}} \boldsymbol{A} \boldsymbol{V}\right|_{m_{2}}^{2}=\left|\boldsymbol{U} \boldsymbol{A} \boldsymbol{V}^{\boldsymbol{H}}\right|_{m_{2}}^{2}$</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="7-3-算子范数"><a href="#7-3-算子范数" class="headerlink" title="7.3 算子范数"></a>7.3 算子范数</h3><ul>
<li><p>向量范数与矩阵范数的相容性：$|A x|_{m} \leq|A|_{m}|x|_{m}$ 是否成立</p>
<ul>
<li><strong>定义</strong>：设 $|\cdot|_a$ 是 $P^n$ 上的向量范数，$|\cdot|_m$ 是 $P^{n\times n}$ 上的矩阵范数，且<script type="math/tex; mode=display">
\|A x\|_{a} \leq\|A\|_{m}\|x\|_{a}\notag</script>则称 $|\cdot|_m$ 为与向量范数 $|\cdot|_a$ 相容的矩阵范数</li>
</ul>
</li>
<li><p>算子范数</p>
<ul>
<li><p>设 $|\cdot|_a$ 是 $P^n$ 上的向量范数，$A\in P^{n\times n}$，则</p>
<script type="math/tex; mode=display">
\|\boldsymbol{A}\|_{a}=\underset{\boldsymbol{x} \neq \boldsymbol{\theta}}{\max } \frac{\|\boldsymbol{A} \boldsymbol{x}\|_{a}}{\|\boldsymbol{x}\|_{a}}\left(=\max _{\|u\|_{a}=1}\|A u\|_{a}\right) \notag</script><p>是与向量范数 $|\cdot|_a$ 相容的矩阵范数</p>
</li>
<li><p>推论：算子范数也是相容的矩阵范数，即 $|AB|_a\le|A|_a|B|_a$</p>
</li>
</ul>
</li>
<li><p>常用算子范数</p>
<ul>
<li>极大列和范数：$|\boldsymbol{A}|_{\mathbf{1}}=\mathbf{m}_{\boldsymbol{j}} \mathbf{x}\left(\sum_{\boldsymbol{i}=1}^{\boldsymbol{n}}\left|\boldsymbol{a}_{i j}\right|\right)$</li>
<li>极大行和范数：$|A|_{\infty}=\max _{i}\left(\sum_{j=1}^{n}\left|a_{i j}\right|\right)$</li>
<li>谱范数：$|\boldsymbol{A}|_{2}=\sqrt{r\left(\boldsymbol{A}^{\boldsymbol{H}} \boldsymbol{A}\right)}$<ul>
<li>谱半径：$r(A)=\max _{i}\left|\lambda_{i}\right|$</li>
<li>$|A|_{2}=\left|A^{H}\right|_{2}=\left|A^{T}\right|_{2}=|\bar{A}|_{2}$</li>
<li>$\left|A^{H} A\right|_{2}=\left|A A^{H}\right|_{2}=|A|_{2}^{2}$</li>
<li>对任意酉矩阵$U,V$，$|\boldsymbol{U} \boldsymbol{A}|_{2}=|\boldsymbol{A} \boldsymbol{V}|_{2}=|\boldsymbol{U} \boldsymbol{A} \boldsymbol{V}|_{2}=|\boldsymbol{A}|_{2}$</li>
</ul>
</li>
</ul>
</li>
<li><p>定理</p>
<ul>
<li>$|\boldsymbol{A}|_{2}=\max _{|x|_{2}=|y|_{2}=\mathbf{1}}\left|\boldsymbol{y}^{\boldsymbol{H}} \boldsymbol{A} \boldsymbol{x}\right|$</li>
<li>$|\boldsymbol{A}|_{2}^{2} \leq|\boldsymbol{A}|_{1}|\boldsymbol{A}|_{\infty}$</li>
</ul>
</li>
</ul>
<hr>
<h2 id="8-矩阵分解"><a href="#8-矩阵分解" class="headerlink" title="8. 矩阵分解"></a>8. 矩阵分解</h2><h3 id="8-1-三角分解"><a href="#8-1-三角分解" class="headerlink" title="8.1 三角分解"></a>8.1 三角分解</h3><ul>
<li>三角矩阵<ul>
<li>逆矩阵仍然是三角矩阵</li>
<li>三角矩阵的积仍是三角矩阵</li>
</ul>
</li>
</ul>
<blockquote>
<p> <strong>定理(LU分解)</strong>：设  $A\in C^{n\times n}$，则 $A$ 可<strong>唯一的</strong>分解为</p>
<script type="math/tex; mode=display">
A=U_1 R \notag</script><p>其中 $U_1$ 为酉矩阵，$R$ 为正线上三角矩阵；或者 A 可以<strong>唯一的</strong>分解为</p>
<script type="math/tex; mode=display">
A = L U_2 \notag</script><p>其中 $U_2$ 为酉矩阵，$L$ 为正线下三角矩阵。</p>
<p><strong>推论 1</strong>：对于实数域，则有类似的 <strong>QR分解</strong></p>
<p><strong>推论 2.1</strong>：对于<strong>实对称</strong>矩阵，存在唯一上三角实矩阵</p>
<script type="math/tex; mode=display">
A = R^T R \notag</script><p><strong>推论 2.2</strong>：正定 <strong>Hermite</strong> 矩阵，存在唯一上三角复矩阵</p>
<script type="math/tex; mode=display">
A = R^H R \notag</script></blockquote>
<ul>
<li>任意矩阵的三角分解（非方阵）</li>
</ul>
<h3 id="8-2-谱分解"><a href="#8-2-谱分解" class="headerlink" title="8.2 谱分解"></a>8.2 谱分解</h3><ul>
<li><strong>单纯矩阵</strong>：代数重数等于几何重数</li>
</ul>
<blockquote>
<p><strong>定理</strong>：设 $A\in C^{n\times n}$ 是<strong>单纯矩阵</strong>，则 $A$ 可以分解为一系列<strong>幂等矩阵</strong> $A_i$ 的加权和</p>
<script type="math/tex; mode=display">
A = \sum_{i=1}^n \lambda_i A_i \notag</script><p>其中 $\lambda_i$ 是 $A$ 的特征值</p>
<p><strong>证明</strong>：由单纯矩阵可知</p>
<script type="math/tex; mode=display">
A=P\Lambda P^{-1}=\left(v_{1}, v_{2}, \cdots, v_{n}\right)\left[\begin{array}{cccc}{\lambda_{1}} & {0} & {\cdots} & {0} \\{0} & {\lambda_{2}} & {\cdots} & {0} \\{\cdots} & {\cdots} & {\cdots} & {\cdots} \\{0} & {0} & {\cdots} & {\lambda_{n}}\end{array}\right]\left(\begin{array}{c}{\omega_{1}^{T}} \\{\omega_{2}^{T}} \\{\vdots} \\{\omega_{n}^{T}}\end{array}\right) \notag</script><p>取 $A_i = v_i w_i^T$，$A_i$ 的性质：</p>
<ul>
<li>幂等性：$A_i^2=A_i$</li>
<li>分离性：$A_i A_j=0(i\ne0)$</li>
<li>可加性：$\sum_{i=1}^n A_i = E_n$</li>
</ul>
<blockquote>
<p><strong>Remarks</strong></p>
<p>这里的幂等矩阵 $A_i$ 可以看作是正交<strong>基</strong>的概念</p>
<p>由前面投影矩阵的定义可知，<strong>每一个 $A_i$ 都是一个投影矩阵</strong>，将任意一个向量 $x$ 投影到 $v_i$ 张成的子空间 $L(v_i)$ 上。因此上面的幂等矩阵分解实际上可以理解为“<strong>特征空间分解</strong>”（笔者瞎想的名词），如何理解呢？把<strong>每个 $A_i$ 看作是矩阵 $A$ 的一个特征子空间（的投影基）</strong>，$Ax$ 实际上就是把 $x$ 投影到各个特征子空间中，然后根据对应的<strong>特征值</strong>进行伸缩，最后再合成一个作用后的向量，即表示 $A$ 对 $x$ 的线性变换。</p>
</blockquote>
<p><strong>定理</strong>：设 $A\in C^{n\times n}$，有 $k$ 个相异的特征值 $\lambda_i(i=1,…,k)$，则 $A$ 是<strong>单纯矩阵</strong>的充要条件是，存在 $k$ 个矩阵矩阵 $A_i$ 满足</p>
<ol>
<li>$A_{i} A_{j}=\left\{\begin{array}{ll}{A_{i}} &amp; {i=j} \\ {0} &amp; {i \neq j}\end{array}\right.$</li>
<li>$\sum_{i=1}^k A_i = E_n$</li>
<li>$A = \sum_{i=1}^k \lambda_i A_i$</li>
</ol>
</blockquote>
<ul>
<li><strong>正规矩阵</strong>：满足 $A^HA=AA^H$ 的矩阵<br><img src="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/normal%20matrix.jpg" alt="正规矩阵"></li>
</ul>
<blockquote>
<p><strong>引理</strong>：设 $A$ 为正规矩阵，$A$ 与 $B$ <strong>酉相似</strong>，则 $B$ 为正规矩阵</p>
<blockquote>
<p> <strong>定理</strong>：任意矩阵 $A\in C^{n\times n}$，存在酉矩阵 $U$ 使得</p>
<script type="math/tex; mode=display">
A=URU^H \notag</script><p>其中 $R$ 为<strong>上三角矩阵</strong>且主对角线元素为 $A$ 的特征值</p>
</blockquote>
<p><strong>引理</strong>：设 $A$ 为正规矩阵且为三角矩阵，则 $A$ 为对角矩阵</p>
<blockquote>
<p><strong>Remarks</strong>：</p>
<p><strong>任意矩阵 $A$ 都与三角阵 $R$ 酉相似</strong>，因此若矩阵 $A$ 为正规阵，则 $R$ 既是正规阵，又是三角阵，则一定是对角阵。</p>
<p>因此，<strong>正规阵一定可以对角化</strong>，由下面的定理可知，可以<strong>酉对角化</strong>的矩阵一定是正规矩阵。</p>
<p>这与普通的可对角化矩阵的区别是什么呢？普通矩阵可对角化的充要条件是代数重数等于几何重数，也即只需要 <strong>n 个线性无关的特征向量</strong>即可($A=PJP^{-1}$)。而正规矩阵则要求<strong>所有特征向量正交</strong>($A=U\Lambda U^H$)！</p>
<p><strong>Remarks</strong></p>
<p>那么<strong>正定矩阵</strong>与<strong>正规矩阵</strong>的区别是什么呢？先看正定矩阵的定义：特征值全部为正数。区别很明显了，一个是从特征值角度，另一个是从特征向量角度，牢记这一点就不会弄混两者了。</p>
<p>凡是具有 $A^HA$ 形式的矩阵，既是<strong>正规矩阵</strong>，又是<strong>正定矩阵</strong>！</p>
</blockquote>
<p><strong>定理</strong>：$A$ 为正规矩阵的充要条件是存在酉矩阵 $U$ 使</p>
<script type="math/tex; mode=display">
A = U \text{diag}(\lambda_1,...,\lambda_n)U^H \notag</script><p>其中 $\lambda_i$ 是 $A$ 的特征值</p>
<p><strong>定理</strong>：$A$ 有 $k$ 个相异特征值，则 $A$ 是正规矩阵的充要条件是存在 $k$ 个矩阵 $A_i$ 满足</p>
<ol>
<li>$A_{i} A_{j}=\left\{\begin{array}{ll}{A_{i}} &amp; {i=j} \\ {0} &amp; {i \neq j}\end{array}\right.$</li>
<li>$\sum_{i=1}^k A_i = E_n$</li>
<li>$A = \sum_{i=1}^k \lambda_i A_i$</li>
<li>$A_i^H = A_i(i=1,…,k)$</li>
</ol>
</blockquote>
<h3 id="8-3-最大秩分解"><a href="#8-3-最大秩分解" class="headerlink" title="8.3 最大秩分解"></a>8.3 最大秩分解</h3><ul>
<li><strong>定理</strong>：设 $A\in C^{m\times n}_r$，则存在矩阵 $B\in C^{m\times r}_r, D\in C^{r\times n}_r$，使得 $A=BD$<ul>
<li>注：可以理解为 $B$ 取出了 $r$ 线性无关的列向量，或者 $D$ 取出了 $r$ 个线性无关的行向量</li>
<li>$(B^HB)^{-1}B^HB=E_r$，可以用于求 $B$ 的左逆，$D$ 同理</li>
</ul>
</li>
</ul>
<h3 id="8-4-奇异值分解"><a href="#8-4-奇异值分解" class="headerlink" title="8.4 奇异值分解"></a>8.4 奇异值分解</h3><ul>
<li><strong>奇异值</strong>：设 $A\in C^{m\times n}_r$，$A^HA$ 的特征值为 $\lambda_{1} \geq \lambda_{2} \geq \cdots \geq \lambda_{r}&gt;\lambda_{r+1}=\cdots=\lambda_{n}=\mathbf{0}$，则称 $\sigma_{i}=\sqrt{\lambda_{i}}(i=1,2, \cdots, r)$ 为 $A$ 的正奇异值（实际上就相当于 A 的“绝对特征值”）</li>
<li><strong>定理</strong>：设 $A\in C^{m\times n}_r$，则有<ol>
<li>$rank(A)=rank(A^HA)=rank(AA^H)$</li>
<li>$A^HA,AA^H$ 的特征值均为非负实数</li>
<li>$A^HA,AA^H$ 的特征值相同</li>
</ol>
</li>
<li><strong>酉等价</strong>：$A,B\in C^{m\times n}$，存在酉矩阵 $U,V$ 使得 $A=UBV$</li>
<li><strong>定理</strong>：若 $A,B$ 酉等价，则它们有相同的奇异值</li>
</ul>
<blockquote>
<p><strong>定理</strong>：设 $A\in C^{m\times n}_r$，$\sigma_1,…,\sigma_r$ 是 $A$ 的 $r$ 个奇异值，则存在酉矩阵 $U\in C^{m\times m},V\in C{n\times n}$，使得</p>
<script type="math/tex; mode=display">
A=U\left[\begin{array}{ll}{D} & {0} \\ {0} & {0}\end{array}\right] V \notag</script><p>其中 $\boldsymbol{D}=\operatorname{diag}\left(\delta_{1}, \delta_{2}, \cdots, \delta_{r}\right),\left|\delta_{i}\right|=\sigma_{i}$</p>
</blockquote>
<hr>
<h2 id="9-特征值估计"><a href="#9-特征值估计" class="headerlink" title="9. 特征值估计"></a>9. 特征值估计</h2><h3 id="9-1-几个不等式"><a href="#9-1-几个不等式" class="headerlink" title="9.1 几个不等式"></a>9.1 几个不等式</h3><ul>
<li><strong>定理 1(Schur 不等式)</strong>：设 $A\in C^{n\times n}$ 的特征值为 $\lambda_1,…,\lambda_n$，则 $\sum_{i=1}^{n}\left|\lambda_{i}\right|^{2} \leq \sum_{i=1}^{n} \sum_{j=1}^{n}\left|a_{i j}\right|^{2}=|A|_{F}^{2}$，等号成立当且仅当 $A$ 为正规矩阵</li>
<li><strong>定理 2(Hirsch)</strong>：设 $A\in C^{n\times n}$，记 $B=\frac{A+A^H}{2},C=\frac{A-A^H}{2}$，$A,B,C$ 特征值分别为 $\{\lambda_i\},\{\mu_i\},\{i\gamma_i\}$，均从大到小排列。则有<ol>
<li>$\left|\lambda_{i}\right| \leq n \max _{i, j}\left|a_{i j}\right|$</li>
<li>$\left|\mathbf{R e} \lambda_{i}\right| \leq n \max _{i, j}\left|b_{i j}\right|$</li>
<li>$\left|\mathbf{I m} \lambda_{i}\right| \leq \boldsymbol{n} \max _{i, j}\left|\boldsymbol{c}_{i j}\right|$</li>
</ol>
</li>
<li><strong>定理 3(Bendixson)</strong>：设 $A\in R^{n\times n}$，则 $A$ 的任一特征值满足 $\left|\mathbf{I m} \lambda_{i}\right| \leq \sqrt{\frac{n(n-1)}{2}} \max _{i, j}\left|c_{i j}\right|$</li>
</ul>
<h3 id="9-2-盖尔圆盘定理"><a href="#9-2-盖尔圆盘定理" class="headerlink" title="9.2 盖尔圆盘定理"></a>9.2 盖尔圆盘定理</h3><ul>
<li><strong>定义 1</strong>：设 $A\in C^{n\times n}$<ul>
<li>行盖尔圆盘：$S_{i}=\left\{z \in C:\left|z-a_{i i}\right| \leq R_{i}=\sum_{j \neq i}\left|a_{i j}\right|\right\}$</li>
<li>列盖尔圆盘：$G_{i}=\left\{z \in C:\left|z-a_{i i}\right| \leq C_{i}=\sum_{j \neq i}\left|a_{j i}\right|\right\}$</li>
</ul>
</li>
</ul>
<blockquote>
<p><strong>定理 1(圆盘定理)</strong>：设 $A\in C^{n\times n}$，则 $A$ 的任一特征值</p>
<script type="math/tex; mode=display">
\lambda_{i} \in \boldsymbol{S}=\bigcup_{j=1}^{n} \boldsymbol{S}_{j} \quad(\boldsymbol{i}=\mathbf{1}, 2, \cdots, \boldsymbol{n}) \notag</script><p>类似的，有</p>
<script type="math/tex; mode=display">
\lambda_{i} \in \left(\bigcup_{j=1}^{n} \boldsymbol{S}_{j}\right) \bigcap \left(\bigcup_{j=1}^{n} \boldsymbol{G}_{j}\right)
\quad(\boldsymbol{i}=\mathbf{1}, 2, \cdots, \boldsymbol{n}) \notag</script><p><strong>定理 2</strong>：设 $n$ 阶方阵 $A$ 的 $n$ 个盖尔圆盘中有 $k$ 个圆盘的并形成一个<strong>连通区域</strong> $G$（圆盘相切也算连通），且它与余下的 $n-k$ 个圆盘都不相交，则在该区域中恰好有 $A$ 的 $k$ 个特征值</p>
<p><strong>证明</strong>：取 $A_{\varepsilon}=D+\varepsilon B,\ \varepsilon \in[0,1]$，而 $A_\varepsilon$ 的特征值 $\lambda_i(A_\varepsilon) = \lambda_i(\varepsilon)$ 时关于 $\varepsilon$ 的<strong>连续函数</strong>，在圆盘随着 $\varepsilon$ 扩大过程中，特征值一直都处于圆盘内部</p>
<p><img src="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/gerschgorin.jpg" alt="gerschgorin"></p>
<p><strong>推论 1</strong>：设 $n$ 阶方阵 $A$ 的 $n$ 个盖尔圆盘两两互不相交，则 $A$ 相似于对角阵</p>
<p><strong>推论 2</strong>：设 $n$ 阶<strong>实矩阵</strong> $A$ 的 $n$ 个盖尔圆盘两两互不相交，则 $A$ 的特征值全部为实数</p>
<p><strong>改进</strong>：可以取 $D=diag(p_1,…,p_n),\ \ p_i&gt;0$，则有 $D^{-1}AD$ 与 $A$ <strong>相似</strong>，因此他们有相同的特征值，可以用 $D^{-1}AD$ 的特征值来估计 $A$。此时可以将某些盖尔圆变小，但是代价就是其他盖尔圆会变大。</p>
</blockquote>
<ul>
<li><strong>行对角占优</strong>：$\left|a_{ii}\right| \geq R_{i}=\sum_{j=1, j \ne i}^{n}\left|a_{i j}\right| \quad(i=1,2, \cdots, n)$</li>
<li><strong>列对角占优</strong>：$\left|a_{ii}\right| \geq C_{i}=\sum_{j=1, j \ne i}^{n}\left|a_{ji}\right| \quad(i=1,2, \cdots, n)$</li>
</ul>
<blockquote>
<p><strong>定理 3</strong>：设 $A\in C^{n\times n}$ <strong>严格</strong>行对角占优，则</p>
<ol>
<li>$A$ 可逆</li>
<li>若 $A$ 所有主对角元都为正数，则 $A$ 的特征值都有正实部</li>
<li>若 $A$ 为 Hermite 矩阵，且所有主对角元都为正数，则 $A$ 的特征值都为正数</li>
</ol>
</blockquote>
<h3 id="9-3-Hermite矩阵特征值的变分特性"><a href="#9-3-Hermite矩阵特征值的变分特性" class="headerlink" title="9.3 Hermite矩阵特征值的变分特性"></a>9.3 Hermite矩阵特征值的变分特性</h3><p>因为Hermite矩阵 $A\in C^{n\times n}$ 的特征值均为实数，所以可以把他们记作（按照大小进行排序）：</p>
<script type="math/tex; mode=display">
\lambda_{\min }=\lambda_{n} \leq \lambda_{n-1} \ldots \leq \lambda_{2} \leq \lambda_{1}=\lambda_{\max } \notag</script><ul>
<li><strong>Rayleigh 商</strong>：$R(x)=\frac{x^{H} A x}{x^{H} x} \quad x \neq 0$<ul>
<li>$\lambda_{n} x^{H} x \leq x^{H} A x \leq \lambda_{1} x^{H} x \quad\left(\forall x \in C^{n}\right)$</li>
<li>$\lambda_{\max }=\lambda_{1}=\max _{x \neq 0} R(x)=\max _{x^{H}} x^{H} A x$</li>
<li>$\lambda_{\min }=\lambda_{n}=\min _{x \neq 0} R(x)=\min _{x^{H} x=1} x^{H} A x$</li>
</ul>
</li>
<li><strong>定理(Courant-Fischer)</strong>：设特征值 $\lambda_1 \le \lambda_2 \le \cdots \le \lambda_n$，则<ul>
<li>$\begin{array}{ccc}{\min } &amp; {\max } &amp; {R(x)=\lambda_{k}} \\ {\omega_{1}, \omega_{2}, \cdots, \omega_{n-k} \in C^{n}} &amp; {x \neq 0, x \in C^{n} \atop {x \perp \omega_{1}, \omega_{2}, \cdots, \omega_{n-k}}} &amp; {} \end{array}$</li>
<li>$\begin{array}{ccc}{\max } &amp; {\min } &amp; {R(x)=\lambda_{k}} \\ {\omega_{1}, \omega_{2}, \cdots, \omega_{n-k} \in C^{n}} &amp; {x \neq 0, x \in C^{n} \atop {x \perp \omega_{1}, \omega_{2}, \cdots, \omega_{n-k}}} &amp; {} \end{array}$</li>
</ul>
</li>
<li><strong>定理(Weyl)</strong>：$\lambda_k(A)+\lambda_n(B)\le\lambda_k(A+B)\le\lambda_k(A)+\lambda_1(B)$</li>
</ul>
<hr>
<h2 id="10-矩阵分析"><a href="#10-矩阵分析" class="headerlink" title="10. 矩阵分析"></a>10. 矩阵分析</h2><h3 id="10-1-矩阵序列与矩阵级数"><a href="#10-1-矩阵序列与矩阵级数" class="headerlink" title="10.1 矩阵序列与矩阵级数"></a>10.1 矩阵序列与矩阵级数</h3><ul>
<li>矩阵序列<ul>
<li><strong>定理</strong>：设 $\Vert\cdot\Vert$ 是 $C^{m\times n}$ 上的任一矩阵范数，矩阵序列 $\{A^{(k)}\}$ 收敛于 $A$ 的充要条件是 $\lim _{k \rightarrow+\infty}\left|A^{(k)}-A\right|=0$</li>
<li><strong>定理</strong>：设 $\lim _{k \rightarrow+\infty} A^{(k)}=A, \lim _{k \rightarrow+\infty} B^{(k)}=B . \alpha, \beta \in C$，则<ul>
<li>$\lim _{k \rightarrow+\infty}\left(\alpha A^{(k)}+\beta B^{(k)}\right)=\alpha A+\beta B$</li>
<li>$\lim _{k \rightarrow+\infty} A^{(k)} B^{(k)}=A B$</li>
<li>当 $A^{(k)}$ 与 $A$ 都可逆时，$\lim _{k \rightarrow+\infty}\left(A^{(k)}\right)^{-1}=A^{-1}$</li>
</ul>
</li>
</ul>
</li>
<li><strong>收敛矩阵</strong>：设 $A\in C^{n\times n}$，若 $\lim _{k \rightarrow \infty} A^{k}=0$，则称 $A$ 为收敛矩阵<ul>
<li><strong>定理</strong>：设 $A\in C^{n\times n}$，则 $A$ 为收敛矩阵的充要条件是 $r(A)&lt;1$</li>
</ul>
</li>
<li><strong>矩阵级数</strong>：$\sum_{k=1}^{\infty} A^{(k)}=A^{(1)}+A^{(2)}+\cdots+A^{(k)}+\cdots$，称 $\boldsymbol{S}^{(\boldsymbol{N})}=\sum_{\boldsymbol{k}=1}^{\boldsymbol{N}} \boldsymbol{A}^{(\boldsymbol{k})}$ 为矩阵级数的部分和，若 $\lim _{N \rightarrow \infty} S^{(N)}=S$ 则称级数<strong>收敛</strong><ul>
<li><strong>定理</strong>：在 $C^{n\times n}$ 中，$\sum_{k=1}^{\infty} A^{(k)}$ 绝对收敛的充要条件是正项级数 $\sum_{k=1}^{\infty}\left|A^{(k)}\right|$ 收敛</li>
<li><strong>定理</strong>：方阵 $A$ 的 Neumann 级数 $\sum_{k=0}^{\infty} A^{k}=I+A+A^{2}+\cdots+A^{k}+\cdots$ 收敛的充要条件是 $r(A)&lt;1$，且收敛时，其和为 $(I-A)^{-1}$</li>
</ul>
</li>
</ul>
<h3 id="10-2-矩阵函数"><a href="#10-2-矩阵函数" class="headerlink" title="10.2 矩阵函数"></a>10.2 矩阵函数</h3><ul>
<li><p>幂级数：设幂级数 $\sum_{k=0}^{\infty} c_{k} z^{k}$ 收敛半径为 $r$，且当 $|z|&lt;r$ 时，幂级数收敛于函数 $f(z)$，即 $f(z)=\sum_{k=0}^{\infty} c_{k} z^{k}, \quad|z|&lt;r$</p>
</li>
<li><p>矩阵幂级数：如果 $A\in C^{n\times n}$ 满足 $r(A)&lt;r$，则称收敛矩阵的矩阵幂级数 $\sum_{k=0}^{\infty} a_{k} A^{k}$ 为矩阵函数，记为 $f(A)$，即 $f(A)=\sum_{k=0}^{\infty} c_{k} A^{k}$，考虑参数 $t$，有 $f(At)=\sum_{k=0}^{\infty} c_{k} (At)^{k}$</p>
<ul>
<li>常用矩阵函数：</li>
<li>$e^{A}=\sum_{k=0}^{\infty} \frac{1}{k !} A^{k}, \quad A \in C^{n \times n}$</li>
<li>$\sin A=\sum_{k=0}^{\infty} \frac{(-1)^{k}}{(2 k+1) !} A^{2 k+1}, \quad A \in C^{n \times n}$</li>
<li>$\cos A=\sum_{k=0}^{\infty} \frac{(-1)^{k}}{(2 k) !} A^{2 k}, \quad A \in C^{n \times n}$</li>
<li>$(E-A)^{-1}=\sum_{k=0}^{\infty} A^{k}, \quad r(A)&lt;1$</li>
<li>$\ln (E+A)=\sum_{k=0}^{\infty} \frac{(-1)^{k}}{k+1} A^{k+1}, \quad r(A)&lt;1$</li>
</ul>
</li>
<li><p>矩阵函数值计算</p>
<ul>
<li><p>相似对角化：设 $P^{-1}AP=diag(\lambda_1,…,\lambda_n)=D$，则 $f(At) = P\cdot diag(f(\lambda_1 t),…,f(\lambda_n t))\cdot P^{-1}$</p>
</li>
<li><p>Jordan标准型：设 $P^{-1}AP=diag(J_1,…,J_s)$，则 </p>
<script type="math/tex; mode=display">
f(A)=P\left(\begin{array}{ccc}
{f\left(J_{1}\right)} & {} & {} \\
{} & {\ddots} & {} \\
{} & {} & {f\left(J_{s}\right)}
\end{array}\right) P^{-1} \notag</script></li>
</ul>
</li>
<li><p>矩阵函数性质</p>
<ul>
<li>如果 $AB=BA$，则<ul>
<li>$e^{A} e^{B}=e^{B} e^{A}=e^{A+B}$</li>
<li>$\cos (A+B)=\cos A \cos B-\sin A \sin B$</li>
<li>$\sin (A+B)=\sin A \cos B+\cos A \sin B$</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h2 id="11-矩阵求逆"><a href="#11-矩阵求逆" class="headerlink" title="11 矩阵求逆"></a>11 矩阵求逆</h2><hr>
<h2 id="Hermite矩阵的性质"><a href="#Hermite矩阵的性质" class="headerlink" title="Hermite矩阵的性质"></a>Hermite矩阵的性质</h2><ul>
<li>一般 Hermite 矩阵<ul>
<li>Hermite 矩阵本身就是<strong>正规矩阵</strong>，因此可以对角化(几何重数等于代数重数)，不同特征向量<strong>正交</strong></li>
<li>特征值均为<strong>实数</strong>（反 Hermite 矩阵的特征值全为虚数）</li>
</ul>
</li>
<li>正定 Hermite 矩阵<ul>
<li>主对角线元素全部大于 0</li>
<li>存在正定 Hermite 矩阵 $B$ 使得 $A=B^2$（可以无穷分解）</li>
<li>$A$ 的任意 k 行和对应的 k 列组成的主子阵是正定的 </li>
</ul>
</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/" rel="tag"># 线性代数</a>
              <a href="/tags/%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90/" rel="tag"># 矩阵分析</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/02/03/statistic/SI_Ch11_Sumproduct/" rel="prev" title="统计推断(十一)  Sum-product algorithm">
      <i class="fa fa-chevron-left"></i> 统计推断(十一)  Sum-product algorithm
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/02/09/tools/laptop/" rel="next" title="笔记本选购指南">
      笔记本选购指南 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-线性代数基础——空间"><span class="nav-text">1. 线性代数基础——空间</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-投影"><span class="nav-text">2. 投影</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Jordan标准型"><span class="nav-text">3. Jordan标准型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-初等矩阵与酉矩阵"><span class="nav-text">4. 初等矩阵与酉矩阵</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-初等变换矩阵"><span class="nav-text">4.1 初等变换矩阵</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-初等酉矩阵"><span class="nav-text">4.2 初等酉矩阵</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-酉变换"><span class="nav-text">4.3 酉变换</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-欧氏空间中的度量（？）"><span class="nav-text">5. 欧氏空间中的度量（？）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-Kronecker积"><span class="nav-text">6. Kronecker积</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-范数"><span class="nav-text">7. 范数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#7-1-向量范数"><span class="nav-text">7.1 向量范数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-2-矩阵范数"><span class="nav-text">7.2 矩阵范数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-3-算子范数"><span class="nav-text">7.3 算子范数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-矩阵分解"><span class="nav-text">8. 矩阵分解</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#8-1-三角分解"><span class="nav-text">8.1 三角分解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-2-谱分解"><span class="nav-text">8.2 谱分解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-3-最大秩分解"><span class="nav-text">8.3 最大秩分解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-4-奇异值分解"><span class="nav-text">8.4 奇异值分解</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-特征值估计"><span class="nav-text">9. 特征值估计</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#9-1-几个不等式"><span class="nav-text">9.1 几个不等式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-2-盖尔圆盘定理"><span class="nav-text">9.2 盖尔圆盘定理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-3-Hermite矩阵特征值的变分特性"><span class="nav-text">9.3 Hermite矩阵特征值的变分特性</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-矩阵分析"><span class="nav-text">10. 矩阵分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#10-1-矩阵序列与矩阵级数"><span class="nav-text">10.1 矩阵序列与矩阵级数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-2-矩阵函数"><span class="nav-text">10.2 矩阵函数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#11-矩阵求逆"><span class="nav-text">11 矩阵求逆</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hermite矩阵的性质"><span class="nav-text">Hermite矩阵的性质</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Glooow</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">70</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">111</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/glooow1024" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;glooow1024" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/mailto:glooow1024@gmail.com" title="E-Mail → mailto:glooow1024@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://glooow.gitee.io/" title="Gitee → https:&#x2F;&#x2F;glooow.gitee.io&#x2F;" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>Gitee</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Glooow</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.0.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.2
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  




  <script src="/js/local-search.js"></script>












  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'iw199srhJNXO53sMUbMWkSxL-gzGzoHsz',
      appKey     : 'ogmo6qYs8PSc7MBFk8A1PDUl',
      placeholder: "Comments here!",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>


  <script type="text/javascript" src="//libs.baidu.com/jquery/1.8.3/jquery.min.js"></script>
  <!--�������������Ч-->
  <!--<script type="text/javascript" src="/js/mouseline.js"></script>-->
  <!--ѩ����Ч-->
  <script type="text/javascript" src="/js/snow1.js"></script>

</body>
</html>
